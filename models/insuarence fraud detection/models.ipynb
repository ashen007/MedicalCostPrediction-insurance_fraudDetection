{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modeling for insurance Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "\n",
    "from sklearn.metrics import f1_score, auc, precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "inpatient_data = pd.read_pickle('../../data/feature engineered/inpatient.pkl')\n",
    "outpatient_data = pd.read_pickle('../../data/feature engineered/outpatient.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((40474, 49), (517737, 47))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpatient_data.shape, outpatient_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 3600x1800 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=[12, 6], dpi=300)\n",
    "sns.countplot(x=inpatient_data['PotentialFraud'], ax=axes[0], palette='binary')\n",
    "axes[0].set_title('inpatient')\n",
    "sns.countplot(x=outpatient_data['PotentialFraud'], ax=axes[1], palette='binary')\n",
    "axes[1].set_title('outpatient')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Inpatient****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((32379, 49), (8095, 49))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(inpatient_data, test_size=0.2)\n",
    "train.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "Y = train['PotentialFraud']\n",
    "X = train.drop('PotentialFraud', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=4, n_repeats=8, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('model', LogisticRegression(max_iter=1000, solver='saga'))],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'model': LogisticRegression(max_iter=1000, solver='saga'),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'model__C': 1.0,\n 'model__class_weight': None,\n 'model__dual': False,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__l1_ratio': None,\n 'model__max_iter': 1000,\n 'model__multi_class': 'auto',\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__random_state': None,\n 'model__solver': 'saga',\n 'model__tol': 0.0001,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline = Pipeline(steps=[('feat_selection', SelectKBest(score_func=mutual_info_classif, k=10))])\n",
    "model_1 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('model', LogisticRegression(max_iter=1000, penalty='l2', solver='saga'))])\n",
    "model_1.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=12, n_splits=6, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x000001D642189E18>))])),\n                                       ('model',\n                                        LogisticRegression(max_iter=1000,\n                                                           solver='saga'))]),\n             n_jobs=-1,\n             param_grid={'model__class_weight': [{0: 1, 1: 1.0},\n                                                 {0: 1, 1: 1.473...\n                                                 {0: 1, 1: 6.2105263157894735},\n                                                 {0: 1, 1: 6.684210526315789},\n                                                 {0: 1, 1: 7.157894736842105},\n                                                 {0: 1, 1: 7.63157894736842},\n                                                 {0: 1, 1: 8.105263157894736},\n                                                 {0: 1, 1: 8.578947368421051},\n                                                 {0: 1, 1: 9.052631578947368},\n                                                 {0: 1, 1: 9.526315789473683},\n                                                 {0: 1, 1: 10.0}]},\n             refit='f1', return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'model__class_weight': [{0: 1, 1: w} for w in np.linspace(1, 10, 20)]}\n",
    "\n",
    "model_1_gs = GridSearchCV(estimator=model_1, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True,\n",
    "                          )\n",
    "model_1_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       18.197283      1.716909         0.023824        0.008864   \n1       19.085700      0.408710         0.023531        0.008236   \n2       20.439193      1.063631         0.024027        0.008745   \n3       18.951122      0.340350         0.025281        0.011367   \n4       19.289672      0.591806         0.021408        0.007920   \n5       18.986841      0.270130         0.023485        0.011245   \n6       19.068139      0.448697         0.024729        0.008978   \n7       19.315148      1.680803         0.023155        0.008008   \n8       19.656072      2.926613         0.022469        0.008919   \n9       19.719491      3.001547         0.023030        0.008496   \n10      19.966644      2.944981         0.025037        0.009653   \n11      20.443372      4.097173         0.021618        0.007850   \n12      19.447071      2.399323         0.022545        0.008451   \n13      21.026567      4.940548         0.024026        0.007950   \n14      20.565958      4.211498         0.024805        0.008700   \n15      20.238146      3.812500         0.024229        0.007463   \n16      22.312007      5.614678         0.026795        0.008011   \n17      20.452194      3.043247         0.023529        0.002505   \n18      22.530033      5.991927         0.023984        0.003012   \n19      21.437139      4.495415         0.024363        0.008119   \n\n        param_model__class_weight  \\\n0                  {0: 1, 1: 1.0}   \n1   {0: 1, 1: 1.4736842105263157}   \n2   {0: 1, 1: 1.9473684210526314}   \n3   {0: 1, 1: 2.4210526315789473}   \n4    {0: 1, 1: 2.894736842105263}   \n5   {0: 1, 1: 3.3684210526315788}   \n6   {0: 1, 1: 3.8421052631578947}   \n7    {0: 1, 1: 4.315789473684211}   \n8    {0: 1, 1: 4.789473684210526}   \n9    {0: 1, 1: 5.263157894736842}   \n10  {0: 1, 1: 5.7368421052631575}   \n11  {0: 1, 1: 6.2105263157894735}   \n12   {0: 1, 1: 6.684210526315789}   \n13   {0: 1, 1: 7.157894736842105}   \n14    {0: 1, 1: 7.63157894736842}   \n15   {0: 1, 1: 8.105263157894736}   \n16   {0: 1, 1: 8.578947368421051}   \n17   {0: 1, 1: 9.052631578947368}   \n18   {0: 1, 1: 9.526315789473683}   \n19                {0: 1, 1: 10.0}   \n\n                                               params  split0_test_precision  \\\n0             {'model__class_weight': {0: 1, 1: 1.0}}               0.815208   \n1   {'model__class_weight': {0: 1, 1: 1.4736842105...               0.653923   \n2   {'model__class_weight': {0: 1, 1: 1.9473684210...               0.582816   \n3   {'model__class_weight': {0: 1, 1: 2.4210526315...               0.581244   \n4   {'model__class_weight': {0: 1, 1: 2.8947368421...               0.581542   \n5   {'model__class_weight': {0: 1, 1: 3.3684210526...               0.581619   \n6   {'model__class_weight': {0: 1, 1: 3.8421052631...               0.581619   \n7   {'model__class_weight': {0: 1, 1: 4.3157894736...               0.581619   \n8   {'model__class_weight': {0: 1, 1: 4.7894736842...               0.581619   \n9   {'model__class_weight': {0: 1, 1: 5.2631578947...               0.581619   \n10  {'model__class_weight': {0: 1, 1: 5.7368421052...               0.581619   \n11  {'model__class_weight': {0: 1, 1: 6.2105263157...               0.581619   \n12  {'model__class_weight': {0: 1, 1: 6.6842105263...               0.581619   \n13  {'model__class_weight': {0: 1, 1: 7.1578947368...               0.581619   \n14  {'model__class_weight': {0: 1, 1: 7.6315789473...               0.581619   \n15  {'model__class_weight': {0: 1, 1: 8.1052631578...               0.581619   \n16  {'model__class_weight': {0: 1, 1: 8.5789473684...               0.581619   \n17  {'model__class_weight': {0: 1, 1: 9.0526315789...               0.581619   \n18  {'model__class_weight': {0: 1, 1: 9.5263157894...               0.581619   \n19           {'model__class_weight': {0: 1, 1: 10.0}}               0.581619   \n\n    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n0                0.817633               0.819680               0.811547  ...   \n1                0.651576               0.647482               0.644089  ...   \n2                0.576134               0.575278               0.573180  ...   \n3                0.571216               0.573850               0.570340  ...   \n4                0.571058               0.573202               0.570052  ...   \n5                0.571058               0.573096               0.570052  ...   \n6                0.571058               0.573096               0.570052  ...   \n7                0.571058               0.573096               0.570052  ...   \n8                0.571058               0.573096               0.570052  ...   \n9                0.571058               0.573096               0.570052  ...   \n10               0.571058               0.573096               0.570052  ...   \n11               0.571058               0.573096               0.570052  ...   \n12               0.571058               0.573096               0.570052  ...   \n13               0.571058               0.573096               0.570052  ...   \n14               0.571058               0.573096               0.570052  ...   \n15               0.571058               0.573096               0.570052  ...   \n16               0.571058               0.573096               0.570052  ...   \n17               0.571058               0.573096               0.570052  ...   \n18               0.571058               0.573096               0.570052  ...   \n19               0.571058               0.573096               0.570052  ...   \n\n    split64_train_f1  split65_train_f1  split66_train_f1  split67_train_f1  \\\n0           0.678956          0.676325          0.678471          0.678041   \n1           0.735558          0.735102          0.732658          0.732594   \n2           0.734166          0.733576          0.731809          0.734426   \n3           0.733889          0.733015          0.731653          0.733669   \n4           0.734321          0.733341          0.732198          0.734178   \n5           0.734321          0.733341          0.732198          0.734161   \n6           0.734321          0.733341          0.732198          0.734161   \n7           0.734321          0.733341          0.732198          0.734161   \n8           0.734321          0.733341          0.732198          0.734161   \n9           0.734321          0.733341          0.732198          0.734161   \n10          0.734321          0.733341          0.732198          0.734161   \n11          0.734321          0.733341          0.732198          0.734161   \n12          0.734321          0.733341          0.732198          0.734161   \n13          0.734321          0.733341          0.732198          0.734161   \n14          0.734321          0.733341          0.732198          0.734161   \n15          0.734321          0.733341          0.732198          0.734161   \n16          0.734321          0.733341          0.732198          0.734161   \n17          0.734321          0.733341          0.732198          0.734161   \n18          0.734321          0.733341          0.732198          0.734161   \n19          0.734321          0.733341          0.732198          0.734161   \n\n    split68_train_f1  split69_train_f1  split70_train_f1  split71_train_f1  \\\n0           0.681243          0.680000          0.677138          0.679449   \n1           0.736233          0.734648          0.734576          0.733945   \n2           0.734241          0.731146          0.732028          0.731004   \n3           0.734146          0.731214          0.731677          0.731100   \n4           0.734492          0.731376          0.731998          0.731286   \n5           0.734517          0.731495          0.732061          0.731286   \n6           0.734517          0.731495          0.732061          0.731286   \n7           0.734517          0.731495          0.732061          0.731286   \n8           0.734517          0.731495          0.732061          0.731286   \n9           0.734517          0.731495          0.732061          0.731286   \n10          0.734517          0.731495          0.732061          0.731286   \n11          0.734517          0.731495          0.732061          0.731286   \n12          0.734517          0.731495          0.732061          0.731286   \n13          0.734517          0.731495          0.732061          0.731286   \n14          0.734517          0.731495          0.732061          0.731286   \n15          0.734517          0.731495          0.732061          0.731286   \n16          0.734517          0.731495          0.732061          0.731286   \n17          0.734517          0.731495          0.732061          0.731286   \n18          0.734517          0.731495          0.732061          0.731286   \n19          0.734517          0.731495          0.732061          0.731286   \n\n    mean_train_f1  std_train_f1  \n0        0.678933      0.001713  \n1        0.734228      0.001733  \n2        0.732528      0.001030  \n3        0.732250      0.001014  \n4        0.732603      0.001018  \n5        0.732620      0.001019  \n6        0.732620      0.001019  \n7        0.732620      0.001019  \n8        0.732620      0.001019  \n9        0.732620      0.001019  \n10       0.732620      0.001019  \n11       0.732612      0.001018  \n12       0.732620      0.001019  \n13       0.732620      0.001019  \n14       0.732620      0.001019  \n15       0.732620      0.001019  \n16       0.732620      0.001019  \n17       0.732620      0.001019  \n18       0.732620      0.001019  \n19       0.732589      0.001082  \n\n[20 rows x 453 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__class_weight</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>split2_test_precision</th>\n      <th>split3_test_precision</th>\n      <th>...</th>\n      <th>split64_train_f1</th>\n      <th>split65_train_f1</th>\n      <th>split66_train_f1</th>\n      <th>split67_train_f1</th>\n      <th>split68_train_f1</th>\n      <th>split69_train_f1</th>\n      <th>split70_train_f1</th>\n      <th>split71_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.197283</td>\n      <td>1.716909</td>\n      <td>0.023824</td>\n      <td>0.008864</td>\n      <td>{0: 1, 1: 1.0}</td>\n      <td>{'model__class_weight': {0: 1, 1: 1.0}}</td>\n      <td>0.815208</td>\n      <td>0.817633</td>\n      <td>0.819680</td>\n      <td>0.811547</td>\n      <td>...</td>\n      <td>0.678956</td>\n      <td>0.676325</td>\n      <td>0.678471</td>\n      <td>0.678041</td>\n      <td>0.681243</td>\n      <td>0.680000</td>\n      <td>0.677138</td>\n      <td>0.679449</td>\n      <td>0.678933</td>\n      <td>0.001713</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19.085700</td>\n      <td>0.408710</td>\n      <td>0.023531</td>\n      <td>0.008236</td>\n      <td>{0: 1, 1: 1.4736842105263157}</td>\n      <td>{'model__class_weight': {0: 1, 1: 1.4736842105...</td>\n      <td>0.653923</td>\n      <td>0.651576</td>\n      <td>0.647482</td>\n      <td>0.644089</td>\n      <td>...</td>\n      <td>0.735558</td>\n      <td>0.735102</td>\n      <td>0.732658</td>\n      <td>0.732594</td>\n      <td>0.736233</td>\n      <td>0.734648</td>\n      <td>0.734576</td>\n      <td>0.733945</td>\n      <td>0.734228</td>\n      <td>0.001733</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.439193</td>\n      <td>1.063631</td>\n      <td>0.024027</td>\n      <td>0.008745</td>\n      <td>{0: 1, 1: 1.9473684210526314}</td>\n      <td>{'model__class_weight': {0: 1, 1: 1.9473684210...</td>\n      <td>0.582816</td>\n      <td>0.576134</td>\n      <td>0.575278</td>\n      <td>0.573180</td>\n      <td>...</td>\n      <td>0.734166</td>\n      <td>0.733576</td>\n      <td>0.731809</td>\n      <td>0.734426</td>\n      <td>0.734241</td>\n      <td>0.731146</td>\n      <td>0.732028</td>\n      <td>0.731004</td>\n      <td>0.732528</td>\n      <td>0.001030</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.951122</td>\n      <td>0.340350</td>\n      <td>0.025281</td>\n      <td>0.011367</td>\n      <td>{0: 1, 1: 2.4210526315789473}</td>\n      <td>{'model__class_weight': {0: 1, 1: 2.4210526315...</td>\n      <td>0.581244</td>\n      <td>0.571216</td>\n      <td>0.573850</td>\n      <td>0.570340</td>\n      <td>...</td>\n      <td>0.733889</td>\n      <td>0.733015</td>\n      <td>0.731653</td>\n      <td>0.733669</td>\n      <td>0.734146</td>\n      <td>0.731214</td>\n      <td>0.731677</td>\n      <td>0.731100</td>\n      <td>0.732250</td>\n      <td>0.001014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19.289672</td>\n      <td>0.591806</td>\n      <td>0.021408</td>\n      <td>0.007920</td>\n      <td>{0: 1, 1: 2.894736842105263}</td>\n      <td>{'model__class_weight': {0: 1, 1: 2.8947368421...</td>\n      <td>0.581542</td>\n      <td>0.571058</td>\n      <td>0.573202</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734178</td>\n      <td>0.734492</td>\n      <td>0.731376</td>\n      <td>0.731998</td>\n      <td>0.731286</td>\n      <td>0.732603</td>\n      <td>0.001018</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>18.986841</td>\n      <td>0.270130</td>\n      <td>0.023485</td>\n      <td>0.011245</td>\n      <td>{0: 1, 1: 3.3684210526315788}</td>\n      <td>{'model__class_weight': {0: 1, 1: 3.3684210526...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>19.068139</td>\n      <td>0.448697</td>\n      <td>0.024729</td>\n      <td>0.008978</td>\n      <td>{0: 1, 1: 3.8421052631578947}</td>\n      <td>{'model__class_weight': {0: 1, 1: 3.8421052631...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>19.315148</td>\n      <td>1.680803</td>\n      <td>0.023155</td>\n      <td>0.008008</td>\n      <td>{0: 1, 1: 4.315789473684211}</td>\n      <td>{'model__class_weight': {0: 1, 1: 4.3157894736...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.656072</td>\n      <td>2.926613</td>\n      <td>0.022469</td>\n      <td>0.008919</td>\n      <td>{0: 1, 1: 4.789473684210526}</td>\n      <td>{'model__class_weight': {0: 1, 1: 4.7894736842...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>19.719491</td>\n      <td>3.001547</td>\n      <td>0.023030</td>\n      <td>0.008496</td>\n      <td>{0: 1, 1: 5.263157894736842}</td>\n      <td>{'model__class_weight': {0: 1, 1: 5.2631578947...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>19.966644</td>\n      <td>2.944981</td>\n      <td>0.025037</td>\n      <td>0.009653</td>\n      <td>{0: 1, 1: 5.7368421052631575}</td>\n      <td>{'model__class_weight': {0: 1, 1: 5.7368421052...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>20.443372</td>\n      <td>4.097173</td>\n      <td>0.021618</td>\n      <td>0.007850</td>\n      <td>{0: 1, 1: 6.2105263157894735}</td>\n      <td>{'model__class_weight': {0: 1, 1: 6.2105263157...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732612</td>\n      <td>0.001018</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>19.447071</td>\n      <td>2.399323</td>\n      <td>0.022545</td>\n      <td>0.008451</td>\n      <td>{0: 1, 1: 6.684210526315789}</td>\n      <td>{'model__class_weight': {0: 1, 1: 6.6842105263...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>21.026567</td>\n      <td>4.940548</td>\n      <td>0.024026</td>\n      <td>0.007950</td>\n      <td>{0: 1, 1: 7.157894736842105}</td>\n      <td>{'model__class_weight': {0: 1, 1: 7.1578947368...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>20.565958</td>\n      <td>4.211498</td>\n      <td>0.024805</td>\n      <td>0.008700</td>\n      <td>{0: 1, 1: 7.63157894736842}</td>\n      <td>{'model__class_weight': {0: 1, 1: 7.6315789473...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20.238146</td>\n      <td>3.812500</td>\n      <td>0.024229</td>\n      <td>0.007463</td>\n      <td>{0: 1, 1: 8.105263157894736}</td>\n      <td>{'model__class_weight': {0: 1, 1: 8.1052631578...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>22.312007</td>\n      <td>5.614678</td>\n      <td>0.026795</td>\n      <td>0.008011</td>\n      <td>{0: 1, 1: 8.578947368421051}</td>\n      <td>{'model__class_weight': {0: 1, 1: 8.5789473684...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>20.452194</td>\n      <td>3.043247</td>\n      <td>0.023529</td>\n      <td>0.002505</td>\n      <td>{0: 1, 1: 9.052631578947368}</td>\n      <td>{'model__class_weight': {0: 1, 1: 9.0526315789...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>22.530033</td>\n      <td>5.991927</td>\n      <td>0.023984</td>\n      <td>0.003012</td>\n      <td>{0: 1, 1: 9.526315789473683}</td>\n      <td>{'model__class_weight': {0: 1, 1: 9.5263157894...</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732620</td>\n      <td>0.001019</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>21.437139</td>\n      <td>4.495415</td>\n      <td>0.024363</td>\n      <td>0.008119</td>\n      <td>{0: 1, 1: 10.0}</td>\n      <td>{'model__class_weight': {0: 1, 1: 10.0}}</td>\n      <td>0.581619</td>\n      <td>0.571058</td>\n      <td>0.573096</td>\n      <td>0.570052</td>\n      <td>...</td>\n      <td>0.734321</td>\n      <td>0.733341</td>\n      <td>0.732198</td>\n      <td>0.734161</td>\n      <td>0.734517</td>\n      <td>0.731495</td>\n      <td>0.732061</td>\n      <td>0.731286</td>\n      <td>0.732589</td>\n      <td>0.001082</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows  453 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_cv = pd.DataFrame(model_1_gs.cv_results_)\n",
    "model_1_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model_1_cv.to_pickle('../../data/temp/model_1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7337678151144008,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x000001D642189E18>))])),\n                 ('model',\n                  LogisticRegression(class_weight={0: 1, 1: 1.4736842105263157},\n                                     max_iter=1000, solver='saga'))]))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_gs.best_score_, model_1_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model two"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('model', SGDClassifier(max_iter=500))],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'model': SGDClassifier(max_iter=500),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'model__alpha': 0.0001,\n 'model__average': False,\n 'model__class_weight': None,\n 'model__early_stopping': False,\n 'model__epsilon': 0.1,\n 'model__eta0': 0.0,\n 'model__fit_intercept': True,\n 'model__l1_ratio': 0.15,\n 'model__learning_rate': 'optimal',\n 'model__loss': 'hinge',\n 'model__max_iter': 500,\n 'model__n_iter_no_change': 5,\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__power_t': 0.5,\n 'model__random_state': None,\n 'model__shuffle': True,\n 'model__tol': 0.001,\n 'model__validation_fraction': 0.1,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('model', SGDClassifier(max_iter=500))])\n",
    "model_2.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=8, n_splits=4, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x0000029388919E18>))])),\n                                       ('model', SGDClassifier(max_iter=500))]),\n             n_jobs=-1,\n             param_grid={'model__alpha': array([0.10118556, 0.09927619, 0.10072713, 0.10065515, 0.09964555,\n       0.09978083, 0.09994515, 0.10048844, 0.10107196, 0.09963315]),\n                         'model__loss': ['log', 'perceptron']},\n             refit='f1', return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_2 = {'model__alpha': np.random.normal(0.1, 0.001, 10),\n",
    "          'model__loss': ['log', 'perceptron'],\n",
    "          }\n",
    "\n",
    "model_2_gs = GridSearchCV(estimator=model_2, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid_2,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True\n",
    "                          )\n",
    "model_2_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       17.266848      0.515404         0.033685        0.009652   \n1       16.254963      0.196355         0.032706        0.005999   \n2       16.405806      0.176464         0.031730        0.009945   \n3       16.387744      0.230214         0.031730        0.006154   \n4       16.650864      0.438987         0.032707        0.007158   \n5       16.559578      0.281697         0.031243        0.003906   \n6       16.477078      0.261913         0.034659        0.006457   \n7       16.624015      0.251293         0.033684        0.006885   \n8       16.644290      0.187287         0.032706        0.005999   \n9       16.616205      0.247717         0.032706        0.008153   \n10      16.621574      0.205075         0.034172        0.009106   \n11      16.562507      0.215608         0.030266        0.006696   \n12      16.787551      0.332656         0.033684        0.011786   \n13      16.739711      0.322062         0.030266        0.007749   \n14      16.632803      0.220538         0.033685        0.006887   \n15      16.731465      0.316700         0.029778        0.008154   \n16      16.758749      0.253708         0.032220        0.006694   \n17      16.754444      0.198052         0.032219        0.005436   \n18      16.691382      0.316524         0.032219        0.003781   \n19      16.648422      0.287991         0.028802        0.007917   \n\n   param_model__alpha param_model__loss  \\\n0            0.101186               log   \n1            0.101186        perceptron   \n2            0.099276               log   \n3            0.099276        perceptron   \n4            0.100727               log   \n5            0.100727        perceptron   \n6            0.100655               log   \n7            0.100655        perceptron   \n8            0.099646               log   \n9            0.099646        perceptron   \n10           0.099781               log   \n11           0.099781        perceptron   \n12           0.099945               log   \n13           0.099945        perceptron   \n14           0.100488               log   \n15           0.100488        perceptron   \n16           0.101072               log   \n17           0.101072        perceptron   \n18           0.099633               log   \n19           0.099633        perceptron   \n\n                                               params  split0_test_precision  \\\n0   {'model__alpha': 0.10118555596661902, 'model__...               0.834423   \n1   {'model__alpha': 0.10118555596661902, 'model__...               0.692613   \n2   {'model__alpha': 0.09927618889972195, 'model__...               0.835728   \n3   {'model__alpha': 0.09927618889972195, 'model__...               0.708887   \n4   {'model__alpha': 0.10072713170975983, 'model__...               0.834163   \n5   {'model__alpha': 0.10072713170975983, 'model__...               0.716189   \n6   {'model__alpha': 0.10065514874108548, 'model__...               0.834107   \n7   {'model__alpha': 0.10065514874108548, 'model__...               0.634933   \n8   {'model__alpha': 0.09964555097901674, 'model__...               0.836255   \n9   {'model__alpha': 0.09964555097901674, 'model__...               0.646242   \n10  {'model__alpha': 0.09978083094624848, 'model__...               0.835196   \n11  {'model__alpha': 0.09978083094624848, 'model__...               0.618005   \n12  {'model__alpha': 0.09994515442067345, 'model__...               0.835723   \n13  {'model__alpha': 0.09994515442067345, 'model__...               0.787324   \n14  {'model__alpha': 0.1004884377981787, 'model__l...               0.833127   \n15  {'model__alpha': 0.1004884377981787, 'model__l...               0.670737   \n16  {'model__alpha': 0.10107195896180728, 'model__...               0.837312   \n17  {'model__alpha': 0.10107195896180728, 'model__...               0.687156   \n18  {'model__alpha': 0.09963314979645999, 'model__...               0.835518   \n19  {'model__alpha': 0.09963314979645999, 'model__...               0.633961   \n\n    split1_test_precision  split2_test_precision  ...  split24_train_f1  \\\n0                0.834614               0.826737  ...          0.675744   \n1                0.662093               0.680765  ...          0.541143   \n2                0.827097               0.829345  ...          0.675504   \n3                0.593756               0.571086  ...          0.679752   \n4                0.836836               0.830964  ...          0.675775   \n5                0.634478               0.659151  ...          0.673160   \n6                0.834972               0.826508  ...          0.675893   \n7                0.645455               0.707946  ...          0.684925   \n8                0.835182               0.826575  ...          0.675662   \n9                0.590069               0.620854  ...          0.635784   \n10               0.783245               0.827307  ...          0.676604   \n11               0.571542               0.674863  ...          0.667869   \n12               0.833896               0.826725  ...          0.677003   \n13               0.551146               0.750690  ...          0.616676   \n14               0.836212               0.829874  ...          0.675238   \n15               0.639646               0.623697  ...          0.658992   \n16               0.836678               0.827478  ...          0.676644   \n17               0.607644               0.603129  ...          0.617885   \n18               0.834820               0.828482  ...          0.675836   \n19               0.717841               0.584335  ...          0.722532   \n\n    split25_train_f1  split26_train_f1  split27_train_f1  split28_train_f1  \\\n0           0.676139          0.676487          0.676831          0.677159   \n1           0.487487          0.678848          0.617766          0.700687   \n2           0.676247          0.676572          0.677391          0.676218   \n3           0.623881          0.595498          0.682291          0.564374   \n4           0.675868          0.675883          0.677204          0.676561   \n5           0.685720          0.598815          0.448820          0.594776   \n6           0.675881          0.676479          0.675758          0.686255   \n7           0.277544          0.640098          0.693415          0.708553   \n8           0.676386          0.676345          0.673846          0.675822   \n9           0.692450          0.670758          0.683639          0.676399   \n10          0.675274          0.675773          0.676488          0.676709   \n11          0.653317          0.569045          0.690814          0.689350   \n12          0.676827          0.675685          0.676599          0.677035   \n13          0.682715          0.654729          0.729465          0.621105   \n14          0.677560          0.679520          0.675317          0.677304   \n15          0.617357          0.658028          0.628875          0.669377   \n16          0.675632          0.676143          0.676616          0.676428   \n17          0.671826          0.655999          0.608118          0.718633   \n18          0.672486          0.677115          0.676650          0.677440   \n19          0.589633          0.712135          0.575157          0.699473   \n\n    split29_train_f1  split30_train_f1  split31_train_f1  mean_train_f1  \\\n0           0.673413          0.678358          0.691201       0.676550   \n1           0.681421          0.684251          0.731656       0.663184   \n2           0.674429          0.677678          0.675967       0.676246   \n3           0.714196          0.599237          0.702434       0.642448   \n4           0.673133          0.679971          0.674705       0.676540   \n5           0.421955          0.633498          0.722592       0.643517   \n6           0.672687          0.678678          0.674860       0.676733   \n7           0.570904          0.681218          0.669104       0.644533   \n8           0.672461          0.679442          0.685263       0.676836   \n9           0.604146          0.633489          0.599073       0.662482   \n10          0.674108          0.679121          0.670641       0.676778   \n11          0.718485          0.649067          0.667150       0.652530   \n12          0.672544          0.679477          0.676664       0.676711   \n13          0.668075          0.715158          0.635394       0.643706   \n14          0.672975          0.679063          0.674610       0.676284   \n15          0.696722          0.690212          0.672529       0.661838   \n16          0.674633          0.678953          0.675115       0.676431   \n17          0.557344          0.720429          0.614567       0.643391   \n18          0.673469          0.679040          0.675633       0.676543   \n19          0.578664          0.680922          0.696064       0.655386   \n\n    std_train_f1  \n0       0.003097  \n1       0.057108  \n2       0.001847  \n3       0.059153  \n4       0.002608  \n5       0.086488  \n6       0.003760  \n7       0.080487  \n8       0.004106  \n9       0.043751  \n10      0.003247  \n11      0.062929  \n12      0.003564  \n13      0.079233  \n14      0.002584  \n15      0.058514  \n16      0.002592  \n17      0.050782  \n18      0.003278  \n19      0.042215  \n\n[20 rows x 214 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__alpha</th>\n      <th>param_model__loss</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>split2_test_precision</th>\n      <th>...</th>\n      <th>split24_train_f1</th>\n      <th>split25_train_f1</th>\n      <th>split26_train_f1</th>\n      <th>split27_train_f1</th>\n      <th>split28_train_f1</th>\n      <th>split29_train_f1</th>\n      <th>split30_train_f1</th>\n      <th>split31_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.266848</td>\n      <td>0.515404</td>\n      <td>0.033685</td>\n      <td>0.009652</td>\n      <td>0.101186</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.10118555596661902, 'model__...</td>\n      <td>0.834423</td>\n      <td>0.834614</td>\n      <td>0.826737</td>\n      <td>...</td>\n      <td>0.675744</td>\n      <td>0.676139</td>\n      <td>0.676487</td>\n      <td>0.676831</td>\n      <td>0.677159</td>\n      <td>0.673413</td>\n      <td>0.678358</td>\n      <td>0.691201</td>\n      <td>0.676550</td>\n      <td>0.003097</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16.254963</td>\n      <td>0.196355</td>\n      <td>0.032706</td>\n      <td>0.005999</td>\n      <td>0.101186</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.10118555596661902, 'model__...</td>\n      <td>0.692613</td>\n      <td>0.662093</td>\n      <td>0.680765</td>\n      <td>...</td>\n      <td>0.541143</td>\n      <td>0.487487</td>\n      <td>0.678848</td>\n      <td>0.617766</td>\n      <td>0.700687</td>\n      <td>0.681421</td>\n      <td>0.684251</td>\n      <td>0.731656</td>\n      <td>0.663184</td>\n      <td>0.057108</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16.405806</td>\n      <td>0.176464</td>\n      <td>0.031730</td>\n      <td>0.009945</td>\n      <td>0.099276</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.09927618889972195, 'model__...</td>\n      <td>0.835728</td>\n      <td>0.827097</td>\n      <td>0.829345</td>\n      <td>...</td>\n      <td>0.675504</td>\n      <td>0.676247</td>\n      <td>0.676572</td>\n      <td>0.677391</td>\n      <td>0.676218</td>\n      <td>0.674429</td>\n      <td>0.677678</td>\n      <td>0.675967</td>\n      <td>0.676246</td>\n      <td>0.001847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.387744</td>\n      <td>0.230214</td>\n      <td>0.031730</td>\n      <td>0.006154</td>\n      <td>0.099276</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.09927618889972195, 'model__...</td>\n      <td>0.708887</td>\n      <td>0.593756</td>\n      <td>0.571086</td>\n      <td>...</td>\n      <td>0.679752</td>\n      <td>0.623881</td>\n      <td>0.595498</td>\n      <td>0.682291</td>\n      <td>0.564374</td>\n      <td>0.714196</td>\n      <td>0.599237</td>\n      <td>0.702434</td>\n      <td>0.642448</td>\n      <td>0.059153</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.650864</td>\n      <td>0.438987</td>\n      <td>0.032707</td>\n      <td>0.007158</td>\n      <td>0.100727</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.10072713170975983, 'model__...</td>\n      <td>0.834163</td>\n      <td>0.836836</td>\n      <td>0.830964</td>\n      <td>...</td>\n      <td>0.675775</td>\n      <td>0.675868</td>\n      <td>0.675883</td>\n      <td>0.677204</td>\n      <td>0.676561</td>\n      <td>0.673133</td>\n      <td>0.679971</td>\n      <td>0.674705</td>\n      <td>0.676540</td>\n      <td>0.002608</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.559578</td>\n      <td>0.281697</td>\n      <td>0.031243</td>\n      <td>0.003906</td>\n      <td>0.100727</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.10072713170975983, 'model__...</td>\n      <td>0.716189</td>\n      <td>0.634478</td>\n      <td>0.659151</td>\n      <td>...</td>\n      <td>0.673160</td>\n      <td>0.685720</td>\n      <td>0.598815</td>\n      <td>0.448820</td>\n      <td>0.594776</td>\n      <td>0.421955</td>\n      <td>0.633498</td>\n      <td>0.722592</td>\n      <td>0.643517</td>\n      <td>0.086488</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>16.477078</td>\n      <td>0.261913</td>\n      <td>0.034659</td>\n      <td>0.006457</td>\n      <td>0.100655</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.10065514874108548, 'model__...</td>\n      <td>0.834107</td>\n      <td>0.834972</td>\n      <td>0.826508</td>\n      <td>...</td>\n      <td>0.675893</td>\n      <td>0.675881</td>\n      <td>0.676479</td>\n      <td>0.675758</td>\n      <td>0.686255</td>\n      <td>0.672687</td>\n      <td>0.678678</td>\n      <td>0.674860</td>\n      <td>0.676733</td>\n      <td>0.003760</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>16.624015</td>\n      <td>0.251293</td>\n      <td>0.033684</td>\n      <td>0.006885</td>\n      <td>0.100655</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.10065514874108548, 'model__...</td>\n      <td>0.634933</td>\n      <td>0.645455</td>\n      <td>0.707946</td>\n      <td>...</td>\n      <td>0.684925</td>\n      <td>0.277544</td>\n      <td>0.640098</td>\n      <td>0.693415</td>\n      <td>0.708553</td>\n      <td>0.570904</td>\n      <td>0.681218</td>\n      <td>0.669104</td>\n      <td>0.644533</td>\n      <td>0.080487</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>16.644290</td>\n      <td>0.187287</td>\n      <td>0.032706</td>\n      <td>0.005999</td>\n      <td>0.099646</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.09964555097901674, 'model__...</td>\n      <td>0.836255</td>\n      <td>0.835182</td>\n      <td>0.826575</td>\n      <td>...</td>\n      <td>0.675662</td>\n      <td>0.676386</td>\n      <td>0.676345</td>\n      <td>0.673846</td>\n      <td>0.675822</td>\n      <td>0.672461</td>\n      <td>0.679442</td>\n      <td>0.685263</td>\n      <td>0.676836</td>\n      <td>0.004106</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>16.616205</td>\n      <td>0.247717</td>\n      <td>0.032706</td>\n      <td>0.008153</td>\n      <td>0.099646</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.09964555097901674, 'model__...</td>\n      <td>0.646242</td>\n      <td>0.590069</td>\n      <td>0.620854</td>\n      <td>...</td>\n      <td>0.635784</td>\n      <td>0.692450</td>\n      <td>0.670758</td>\n      <td>0.683639</td>\n      <td>0.676399</td>\n      <td>0.604146</td>\n      <td>0.633489</td>\n      <td>0.599073</td>\n      <td>0.662482</td>\n      <td>0.043751</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>16.621574</td>\n      <td>0.205075</td>\n      <td>0.034172</td>\n      <td>0.009106</td>\n      <td>0.099781</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.09978083094624848, 'model__...</td>\n      <td>0.835196</td>\n      <td>0.783245</td>\n      <td>0.827307</td>\n      <td>...</td>\n      <td>0.676604</td>\n      <td>0.675274</td>\n      <td>0.675773</td>\n      <td>0.676488</td>\n      <td>0.676709</td>\n      <td>0.674108</td>\n      <td>0.679121</td>\n      <td>0.670641</td>\n      <td>0.676778</td>\n      <td>0.003247</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>16.562507</td>\n      <td>0.215608</td>\n      <td>0.030266</td>\n      <td>0.006696</td>\n      <td>0.099781</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.09978083094624848, 'model__...</td>\n      <td>0.618005</td>\n      <td>0.571542</td>\n      <td>0.674863</td>\n      <td>...</td>\n      <td>0.667869</td>\n      <td>0.653317</td>\n      <td>0.569045</td>\n      <td>0.690814</td>\n      <td>0.689350</td>\n      <td>0.718485</td>\n      <td>0.649067</td>\n      <td>0.667150</td>\n      <td>0.652530</td>\n      <td>0.062929</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>16.787551</td>\n      <td>0.332656</td>\n      <td>0.033684</td>\n      <td>0.011786</td>\n      <td>0.099945</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.09994515442067345, 'model__...</td>\n      <td>0.835723</td>\n      <td>0.833896</td>\n      <td>0.826725</td>\n      <td>...</td>\n      <td>0.677003</td>\n      <td>0.676827</td>\n      <td>0.675685</td>\n      <td>0.676599</td>\n      <td>0.677035</td>\n      <td>0.672544</td>\n      <td>0.679477</td>\n      <td>0.676664</td>\n      <td>0.676711</td>\n      <td>0.003564</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>16.739711</td>\n      <td>0.322062</td>\n      <td>0.030266</td>\n      <td>0.007749</td>\n      <td>0.099945</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.09994515442067345, 'model__...</td>\n      <td>0.787324</td>\n      <td>0.551146</td>\n      <td>0.750690</td>\n      <td>...</td>\n      <td>0.616676</td>\n      <td>0.682715</td>\n      <td>0.654729</td>\n      <td>0.729465</td>\n      <td>0.621105</td>\n      <td>0.668075</td>\n      <td>0.715158</td>\n      <td>0.635394</td>\n      <td>0.643706</td>\n      <td>0.079233</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>16.632803</td>\n      <td>0.220538</td>\n      <td>0.033685</td>\n      <td>0.006887</td>\n      <td>0.100488</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.1004884377981787, 'model__l...</td>\n      <td>0.833127</td>\n      <td>0.836212</td>\n      <td>0.829874</td>\n      <td>...</td>\n      <td>0.675238</td>\n      <td>0.677560</td>\n      <td>0.679520</td>\n      <td>0.675317</td>\n      <td>0.677304</td>\n      <td>0.672975</td>\n      <td>0.679063</td>\n      <td>0.674610</td>\n      <td>0.676284</td>\n      <td>0.002584</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16.731465</td>\n      <td>0.316700</td>\n      <td>0.029778</td>\n      <td>0.008154</td>\n      <td>0.100488</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.1004884377981787, 'model__l...</td>\n      <td>0.670737</td>\n      <td>0.639646</td>\n      <td>0.623697</td>\n      <td>...</td>\n      <td>0.658992</td>\n      <td>0.617357</td>\n      <td>0.658028</td>\n      <td>0.628875</td>\n      <td>0.669377</td>\n      <td>0.696722</td>\n      <td>0.690212</td>\n      <td>0.672529</td>\n      <td>0.661838</td>\n      <td>0.058514</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16.758749</td>\n      <td>0.253708</td>\n      <td>0.032220</td>\n      <td>0.006694</td>\n      <td>0.101072</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.10107195896180728, 'model__...</td>\n      <td>0.837312</td>\n      <td>0.836678</td>\n      <td>0.827478</td>\n      <td>...</td>\n      <td>0.676644</td>\n      <td>0.675632</td>\n      <td>0.676143</td>\n      <td>0.676616</td>\n      <td>0.676428</td>\n      <td>0.674633</td>\n      <td>0.678953</td>\n      <td>0.675115</td>\n      <td>0.676431</td>\n      <td>0.002592</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16.754444</td>\n      <td>0.198052</td>\n      <td>0.032219</td>\n      <td>0.005436</td>\n      <td>0.101072</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.10107195896180728, 'model__...</td>\n      <td>0.687156</td>\n      <td>0.607644</td>\n      <td>0.603129</td>\n      <td>...</td>\n      <td>0.617885</td>\n      <td>0.671826</td>\n      <td>0.655999</td>\n      <td>0.608118</td>\n      <td>0.718633</td>\n      <td>0.557344</td>\n      <td>0.720429</td>\n      <td>0.614567</td>\n      <td>0.643391</td>\n      <td>0.050782</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>16.691382</td>\n      <td>0.316524</td>\n      <td>0.032219</td>\n      <td>0.003781</td>\n      <td>0.099633</td>\n      <td>log</td>\n      <td>{'model__alpha': 0.09963314979645999, 'model__...</td>\n      <td>0.835518</td>\n      <td>0.834820</td>\n      <td>0.828482</td>\n      <td>...</td>\n      <td>0.675836</td>\n      <td>0.672486</td>\n      <td>0.677115</td>\n      <td>0.676650</td>\n      <td>0.677440</td>\n      <td>0.673469</td>\n      <td>0.679040</td>\n      <td>0.675633</td>\n      <td>0.676543</td>\n      <td>0.003278</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>16.648422</td>\n      <td>0.287991</td>\n      <td>0.028802</td>\n      <td>0.007917</td>\n      <td>0.099633</td>\n      <td>perceptron</td>\n      <td>{'model__alpha': 0.09963314979645999, 'model__...</td>\n      <td>0.633961</td>\n      <td>0.717841</td>\n      <td>0.584335</td>\n      <td>...</td>\n      <td>0.722532</td>\n      <td>0.589633</td>\n      <td>0.712135</td>\n      <td>0.575157</td>\n      <td>0.699473</td>\n      <td>0.578664</td>\n      <td>0.680922</td>\n      <td>0.696064</td>\n      <td>0.655386</td>\n      <td>0.042215</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows  214 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_cv = pd.DataFrame(model_2_gs.cv_results_)\n",
    "model_2_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_2_cv.to_pickle('../../data/temp/model_2.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6766514607634814,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x0000029388919E18>))])),\n                 ('model',\n                  SGDClassifier(alpha=0.09978083094624848, loss='log',\n                                max_iter=500))]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_gs.best_score_, model_2_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model three"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('poly', PolynomialFeatures()),\n  ('model',\n   LogisticRegression(class_weight={0: 0, 1: 1.4736842105263157}, solver='saga'))],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'poly': PolynomialFeatures(),\n 'model': LogisticRegression(class_weight={0: 0, 1: 1.4736842105263157}, solver='saga'),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'poly__degree': 2,\n 'poly__include_bias': True,\n 'poly__interaction_only': False,\n 'poly__order': 'C',\n 'model__C': 1.0,\n 'model__class_weight': {0: 0, 1: 1.4736842105263157},\n 'model__dual': False,\n 'model__fit_intercept': True,\n 'model__intercept_scaling': 1,\n 'model__l1_ratio': None,\n 'model__max_iter': 100,\n 'model__multi_class': 'auto',\n 'model__n_jobs': None,\n 'model__penalty': 'l2',\n 'model__random_state': None,\n 'model__solver': 'saga',\n 'model__tol': 0.0001,\n 'model__verbose': 0,\n 'model__warm_start': False}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('poly', PolynomialFeatures()),\n",
    "                          ('model', LogisticRegression(class_weight={0: 0, 1: 1.4736842105263157}, penalty='l2',\n",
    "                                                       solver='saga'))])\n",
    "model_3.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=8, n_splits=4, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x000001C0E0029D90>))])),\n                                       ('poly', PolynomialFeatures()),\n                                       ('model',\n                                        LogisticRegression(class_weight={0: 0,\n                                                                         1: 1.4736842105263157},\n                                                           solver='saga'))]),\n             n_jobs=-1, param_grid={'poly__degree': [2, 3, 4, 5]}, refit='f1',\n             return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_3 = {'poly__degree': [2, 3, 4, 5]}\n",
    "\n",
    "model_3_gs = GridSearchCV(estimator=model_3, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid_3,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True\n",
    "                          )\n",
    "model_3_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0      20.243378      1.296572         0.045399        0.009848   \n1      36.746719      0.226800         0.071272        0.011003   \n2      87.527245      0.501526         0.189896        0.024425   \n3     231.261092      4.522659         0.447026        0.080511   \n\n  param_poly__degree               params  split0_test_precision  \\\n0                  2  {'poly__degree': 2}               0.577764   \n1                  3  {'poly__degree': 3}               0.577764   \n2                  4  {'poly__degree': 4}               0.577764   \n3                  5  {'poly__degree': 5}               0.612047   \n\n   split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n0               0.586905               0.577764               0.573882  ...   \n1               0.586905               0.577764               0.573882  ...   \n2               0.586905               0.577764               0.573882  ...   \n3               0.600405               0.577764               0.588322  ...   \n\n   split24_train_f1  split25_train_f1  split26_train_f1  split27_train_f1  \\\n0          0.734087          0.730879          0.735110          0.733672   \n1          0.734087          0.730879          0.735110          0.733672   \n2          0.734087          0.730879          0.735110          0.733672   \n3          0.734062          0.723451          0.734962          0.733707   \n\n   split28_train_f1  split29_train_f1  split30_train_f1  split31_train_f1  \\\n0          0.734351          0.734252          0.731807          0.733342   \n1          0.734351          0.734252          0.731585          0.733342   \n2          0.734351          0.734252          0.731807          0.733342   \n3          0.726884          0.726117          0.731807          0.733098   \n\n   mean_train_f1  std_train_f1  \n0       0.733438      0.001240  \n1       0.733432      0.001251  \n2       0.733438      0.001240  \n3       0.727313      0.008628  \n\n[4 rows x 213 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_poly__degree</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>split2_test_precision</th>\n      <th>split3_test_precision</th>\n      <th>...</th>\n      <th>split24_train_f1</th>\n      <th>split25_train_f1</th>\n      <th>split26_train_f1</th>\n      <th>split27_train_f1</th>\n      <th>split28_train_f1</th>\n      <th>split29_train_f1</th>\n      <th>split30_train_f1</th>\n      <th>split31_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20.243378</td>\n      <td>1.296572</td>\n      <td>0.045399</td>\n      <td>0.009848</td>\n      <td>2</td>\n      <td>{'poly__degree': 2}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>0.573882</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.735110</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.001240</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36.746719</td>\n      <td>0.226800</td>\n      <td>0.071272</td>\n      <td>0.011003</td>\n      <td>3</td>\n      <td>{'poly__degree': 3}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>0.573882</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.735110</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731585</td>\n      <td>0.733342</td>\n      <td>0.733432</td>\n      <td>0.001251</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87.527245</td>\n      <td>0.501526</td>\n      <td>0.189896</td>\n      <td>0.024425</td>\n      <td>4</td>\n      <td>{'poly__degree': 4}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>0.573882</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.735110</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.001240</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>231.261092</td>\n      <td>4.522659</td>\n      <td>0.447026</td>\n      <td>0.080511</td>\n      <td>5</td>\n      <td>{'poly__degree': 5}</td>\n      <td>0.612047</td>\n      <td>0.600405</td>\n      <td>0.577764</td>\n      <td>0.588322</td>\n      <td>...</td>\n      <td>0.734062</td>\n      <td>0.723451</td>\n      <td>0.734962</td>\n      <td>0.733707</td>\n      <td>0.726884</td>\n      <td>0.726117</td>\n      <td>0.731807</td>\n      <td>0.733098</td>\n      <td>0.727313</td>\n      <td>0.008628</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows  213 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_gs_cv = pd.DataFrame(model_3_gs.cv_results_)\n",
    "model_3_gs_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model_3_gs_cv.to_pickle('../../data/temp/model_3.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7334280381149567,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x000001C0E0029D90>))])),\n                 ('poly', PolynomialFeatures()),\n                 ('model',\n                  LogisticRegression(class_weight={0: 0, 1: 1.4736842105263157},\n                                     solver='saga'))]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_gs.best_score_, model_3_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model four"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('model', SVC(class_weight={0: 0, 1: 1.4736842105263157}))],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'model': SVC(class_weight={0: 0, 1: 1.4736842105263157}),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'model__C': 1.0,\n 'model__break_ties': False,\n 'model__cache_size': 200,\n 'model__class_weight': {0: 0, 1: 1.4736842105263157},\n 'model__coef0': 0.0,\n 'model__decision_function_shape': 'ovr',\n 'model__degree': 3,\n 'model__gamma': 'scale',\n 'model__kernel': 'rbf',\n 'model__max_iter': -1,\n 'model__probability': False,\n 'model__random_state': None,\n 'model__shrinking': True,\n 'model__tol': 0.001,\n 'model__verbose': False}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('model', SVC(class_weight={0: 0, 1: 1.4736842105263157}))])\n",
    "model_4.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=8, n_splits=4, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x000001C0E0029D90>))])),\n                                       ('model',\n                                        SVC(class_weight={0: 0,\n                                                          1: 1.4736842105263157}))]),\n             n_jobs=-1,\n             param_grid={'model__C': array([ 1.        ,  1.81818182,  2.63636364,  3.45454545,  4.27272727,\n        5.09090909,  5.90909091,  6.72727273,  7.54545455,  8.36363636,\n        9.18181818, 10.        ]),\n                         'model__degree': [3, 4, 5]},\n             refit='f1', return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4 = {'model__C': np.linspace(1, 10, 12),\n",
    "          'model__degree': [3, 4, 5]}\n",
    "\n",
    "model_4_gs = GridSearchCV(estimator=model_4, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid_4,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True\n",
    "                          )\n",
    "model_4_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       42.492191      0.930810         0.041495        0.007419   \n1       43.433133      0.478698         0.041495        0.009250   \n2       42.990854      0.371353         0.041983        0.007242   \n3       42.699494      0.753821         0.042960        0.006764   \n4       42.548427      1.089397         0.041495        0.008384   \n5       43.525415      1.487601         0.041497        0.011311   \n6       43.673092      0.788402         0.040031        0.008678   \n7       42.791194      0.659240         0.039543        0.008720   \n8       42.376492      0.681954         0.043936        0.010651   \n9       41.863063      0.986847         0.041007        0.009365   \n10      41.422403      0.720028         0.040518        0.009453   \n11      41.632775      0.731734         0.041007        0.009364   \n12      43.627658      2.362819         0.040749        0.013978   \n13      42.035512      0.896538         0.039542        0.008718   \n14      42.197584      0.607116         0.039542        0.007796   \n15      42.406830      0.654658         0.038565        0.007795   \n16      42.321373      0.867689         0.038566        0.008719   \n17      42.192731      0.702864         0.041495        0.007419   \n18      42.156578      0.776284         0.038565        0.008719   \n19      42.092002      0.711634         0.040519        0.007672   \n20      42.968819      1.145943         0.046096        0.016727   \n21      43.651498      2.121176         0.042959        0.010332   \n22      41.907015      0.744578         0.040030        0.008678   \n23      42.171835      0.710066         0.040030        0.010286   \n24      42.157184      0.661962         0.040028        0.009513   \n25      41.867960      0.741843         0.041983        0.008227   \n26      41.732363      0.736960         0.041982        0.009106   \n27      43.563962      2.274593         0.046864        0.031966   \n28      42.305956      0.871946         0.042960        0.008732   \n29      42.364049      0.874619         0.039542        0.007795   \n30      42.622309      1.160567         0.041007        0.008511   \n31      42.938620      1.340953         0.041494        0.008384   \n32      42.626194      0.601804         0.038567        0.008721   \n33      42.393827      0.759404         0.041494        0.009250   \n34      41.448624      1.270370         0.040030        0.007749   \n35      42.248842      3.279531         0.039543        0.010320   \n\n   param_model__C param_model__degree  \\\n0        1.000000                   3   \n1        1.000000                   4   \n2        1.000000                   5   \n3        1.818182                   3   \n4        1.818182                   4   \n5        1.818182                   5   \n6        2.636364                   3   \n7        2.636364                   4   \n8        2.636364                   5   \n9        3.454545                   3   \n10       3.454545                   4   \n11       3.454545                   5   \n12       4.272727                   3   \n13       4.272727                   4   \n14       4.272727                   5   \n15       5.090909                   3   \n16       5.090909                   4   \n17       5.090909                   5   \n18       5.909091                   3   \n19       5.909091                   4   \n20       5.909091                   5   \n21       6.727273                   3   \n22       6.727273                   4   \n23       6.727273                   5   \n24       7.545455                   3   \n25       7.545455                   4   \n26       7.545455                   5   \n27       8.363636                   3   \n28       8.363636                   4   \n29       8.363636                   5   \n30       9.181818                   3   \n31       9.181818                   4   \n32       9.181818                   5   \n33      10.000000                   3   \n34      10.000000                   4   \n35      10.000000                   5   \n\n                                               params  split0_test_precision  \\\n0               {'model__C': 1.0, 'model__degree': 3}               0.577764   \n1               {'model__C': 1.0, 'model__degree': 4}               0.577764   \n2               {'model__C': 1.0, 'model__degree': 5}               0.577764   \n3   {'model__C': 1.8181818181818183, 'model__degre...               0.577764   \n4   {'model__C': 1.8181818181818183, 'model__degre...               0.577764   \n5   {'model__C': 1.8181818181818183, 'model__degre...               0.577764   \n6   {'model__C': 2.6363636363636367, 'model__degre...               0.577764   \n7   {'model__C': 2.6363636363636367, 'model__degre...               0.577764   \n8   {'model__C': 2.6363636363636367, 'model__degre...               0.577764   \n9   {'model__C': 3.4545454545454546, 'model__degre...               0.577764   \n10  {'model__C': 3.4545454545454546, 'model__degre...               0.577764   \n11  {'model__C': 3.4545454545454546, 'model__degre...               0.577764   \n12  {'model__C': 4.272727272727273, 'model__degree...               0.577764   \n13  {'model__C': 4.272727272727273, 'model__degree...               0.577764   \n14  {'model__C': 4.272727272727273, 'model__degree...               0.577764   \n15  {'model__C': 5.090909090909091, 'model__degree...               0.577764   \n16  {'model__C': 5.090909090909091, 'model__degree...               0.577764   \n17  {'model__C': 5.090909090909091, 'model__degree...               0.577764   \n18  {'model__C': 5.909090909090909, 'model__degree...               0.577764   \n19  {'model__C': 5.909090909090909, 'model__degree...               0.577764   \n20  {'model__C': 5.909090909090909, 'model__degree...               0.577764   \n21  {'model__C': 6.7272727272727275, 'model__degre...               0.577764   \n22  {'model__C': 6.7272727272727275, 'model__degre...               0.577764   \n23  {'model__C': 6.7272727272727275, 'model__degre...               0.577764   \n24  {'model__C': 7.545454545454546, 'model__degree...               0.577764   \n25  {'model__C': 7.545454545454546, 'model__degree...               0.577764   \n26  {'model__C': 7.545454545454546, 'model__degree...               0.577764   \n27  {'model__C': 8.363636363636363, 'model__degree...               0.577764   \n28  {'model__C': 8.363636363636363, 'model__degree...               0.577764   \n29  {'model__C': 8.363636363636363, 'model__degree...               0.577764   \n30  {'model__C': 9.181818181818182, 'model__degree...               0.577764   \n31  {'model__C': 9.181818181818182, 'model__degree...               0.577764   \n32  {'model__C': 9.181818181818182, 'model__degree...               0.577764   \n33             {'model__C': 10.0, 'model__degree': 3}               0.577764   \n34             {'model__C': 10.0, 'model__degree': 4}               0.577764   \n35             {'model__C': 10.0, 'model__degree': 5}               0.577764   \n\n    split1_test_precision  split2_test_precision  ...  split24_train_f1  \\\n0                0.586905               0.577764  ...          0.734087   \n1                0.586905               0.577764  ...          0.734087   \n2                0.586905               0.577764  ...          0.734087   \n3                0.586905               0.577764  ...          0.734087   \n4                0.586905               0.577764  ...          0.734087   \n5                0.586905               0.577764  ...          0.734087   \n6                0.586905               0.577764  ...          0.734087   \n7                0.586905               0.577764  ...          0.734087   \n8                0.586905               0.577764  ...          0.734087   \n9                0.586905               0.577764  ...          0.734087   \n10               0.586905               0.577764  ...          0.734087   \n11               0.586905               0.577764  ...          0.734087   \n12               0.586905               0.577764  ...          0.734087   \n13               0.586905               0.577764  ...          0.734087   \n14               0.586905               0.577764  ...          0.734087   \n15               0.586905               0.577764  ...          0.734087   \n16               0.586905               0.577764  ...          0.734087   \n17               0.586905               0.577764  ...          0.734087   \n18               0.586905               0.577764  ...          0.734087   \n19               0.586905               0.577764  ...          0.734087   \n20               0.586905               0.577764  ...          0.734087   \n21               0.586905               0.577764  ...          0.734087   \n22               0.586905               0.577764  ...          0.734087   \n23               0.586905               0.577764  ...          0.734087   \n24               0.586905               0.577764  ...          0.734087   \n25               0.586905               0.577764  ...          0.734087   \n26               0.586905               0.577764  ...          0.734087   \n27               0.586905               0.577764  ...          0.734087   \n28               0.586905               0.577764  ...          0.734087   \n29               0.586905               0.577764  ...          0.734087   \n30               0.586905               0.577764  ...          0.734087   \n31               0.586905               0.577764  ...          0.734087   \n32               0.586905               0.577764  ...          0.734087   \n33               0.586905               0.577764  ...          0.734087   \n34               0.586905               0.577764  ...          0.734087   \n35               0.586905               0.577764  ...          0.734087   \n\n    split25_train_f1  split26_train_f1  split27_train_f1  split28_train_f1  \\\n0           0.730879           0.73511          0.733672          0.734351   \n1           0.730879           0.73511          0.733672          0.734351   \n2           0.730879           0.73511          0.733672          0.734351   \n3           0.730879           0.73511          0.733672          0.734351   \n4           0.730879           0.73511          0.733672          0.734351   \n5           0.730879           0.73511          0.733672          0.734351   \n6           0.730879           0.73511          0.733672          0.734351   \n7           0.730879           0.73511          0.733672          0.734351   \n8           0.730879           0.73511          0.733672          0.734351   \n9           0.730879           0.73511          0.733672          0.734351   \n10          0.730879           0.73511          0.733672          0.734351   \n11          0.730879           0.73511          0.733672          0.734351   \n12          0.730879           0.73511          0.733672          0.734351   \n13          0.730879           0.73511          0.733672          0.734351   \n14          0.730879           0.73511          0.733672          0.734351   \n15          0.730879           0.73511          0.733672          0.734351   \n16          0.730879           0.73511          0.733672          0.734351   \n17          0.730879           0.73511          0.733672          0.734351   \n18          0.730879           0.73511          0.733672          0.734351   \n19          0.730879           0.73511          0.733672          0.734351   \n20          0.730879           0.73511          0.733672          0.734351   \n21          0.730879           0.73511          0.733672          0.734351   \n22          0.730879           0.73511          0.733672          0.734351   \n23          0.730879           0.73511          0.733672          0.734351   \n24          0.730879           0.73511          0.733672          0.734351   \n25          0.730879           0.73511          0.733672          0.734351   \n26          0.730879           0.73511          0.733672          0.734351   \n27          0.730879           0.73511          0.733672          0.734351   \n28          0.730879           0.73511          0.733672          0.734351   \n29          0.730879           0.73511          0.733672          0.734351   \n30          0.730879           0.73511          0.733672          0.734351   \n31          0.730879           0.73511          0.733672          0.734351   \n32          0.730879           0.73511          0.733672          0.734351   \n33          0.730879           0.73511          0.733672          0.734351   \n34          0.730879           0.73511          0.733672          0.734351   \n35          0.730879           0.73511          0.733672          0.734351   \n\n    split29_train_f1  split30_train_f1  split31_train_f1  mean_train_f1  \\\n0           0.734252          0.731807          0.733342       0.733438   \n1           0.734252          0.731807          0.733342       0.733438   \n2           0.734252          0.731807          0.733342       0.733438   \n3           0.734252          0.731807          0.733342       0.733438   \n4           0.734252          0.731807          0.733342       0.733438   \n5           0.734252          0.731807          0.733342       0.733438   \n6           0.734252          0.731807          0.733342       0.733438   \n7           0.734252          0.731807          0.733342       0.733438   \n8           0.734252          0.731807          0.733342       0.733438   \n9           0.734252          0.731807          0.733342       0.733438   \n10          0.734252          0.731807          0.733342       0.733438   \n11          0.734252          0.731807          0.733342       0.733438   \n12          0.734252          0.731807          0.733342       0.733438   \n13          0.734252          0.731807          0.733342       0.733438   \n14          0.734252          0.731807          0.733342       0.733438   \n15          0.734252          0.731807          0.733342       0.733438   \n16          0.734252          0.731807          0.733342       0.733438   \n17          0.734252          0.731807          0.733342       0.733438   \n18          0.734252          0.731807          0.733342       0.733438   \n19          0.734252          0.731807          0.733342       0.733438   \n20          0.734252          0.731807          0.733342       0.733438   \n21          0.734252          0.731807          0.733342       0.733438   \n22          0.734252          0.731807          0.733342       0.733438   \n23          0.734252          0.731807          0.733342       0.733438   \n24          0.734252          0.731807          0.733342       0.733438   \n25          0.734252          0.731807          0.733342       0.733438   \n26          0.734252          0.731807          0.733342       0.733438   \n27          0.734252          0.731807          0.733342       0.733438   \n28          0.734252          0.731807          0.733342       0.733438   \n29          0.734252          0.731807          0.733342       0.733438   \n30          0.734252          0.731807          0.733342       0.733438   \n31          0.734252          0.731807          0.733342       0.733438   \n32          0.734252          0.731807          0.733342       0.733438   \n33          0.734252          0.731807          0.733342       0.733438   \n34          0.734252          0.731807          0.733342       0.733438   \n35          0.734252          0.731807          0.733342       0.733438   \n\n    std_train_f1  \n0        0.00124  \n1        0.00124  \n2        0.00124  \n3        0.00124  \n4        0.00124  \n5        0.00124  \n6        0.00124  \n7        0.00124  \n8        0.00124  \n9        0.00124  \n10       0.00124  \n11       0.00124  \n12       0.00124  \n13       0.00124  \n14       0.00124  \n15       0.00124  \n16       0.00124  \n17       0.00124  \n18       0.00124  \n19       0.00124  \n20       0.00124  \n21       0.00124  \n22       0.00124  \n23       0.00124  \n24       0.00124  \n25       0.00124  \n26       0.00124  \n27       0.00124  \n28       0.00124  \n29       0.00124  \n30       0.00124  \n31       0.00124  \n32       0.00124  \n33       0.00124  \n34       0.00124  \n35       0.00124  \n\n[36 rows x 214 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__C</th>\n      <th>param_model__degree</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>split2_test_precision</th>\n      <th>...</th>\n      <th>split24_train_f1</th>\n      <th>split25_train_f1</th>\n      <th>split26_train_f1</th>\n      <th>split27_train_f1</th>\n      <th>split28_train_f1</th>\n      <th>split29_train_f1</th>\n      <th>split30_train_f1</th>\n      <th>split31_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42.492191</td>\n      <td>0.930810</td>\n      <td>0.041495</td>\n      <td>0.007419</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>{'model__C': 1.0, 'model__degree': 3}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43.433133</td>\n      <td>0.478698</td>\n      <td>0.041495</td>\n      <td>0.009250</td>\n      <td>1.000000</td>\n      <td>4</td>\n      <td>{'model__C': 1.0, 'model__degree': 4}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42.990854</td>\n      <td>0.371353</td>\n      <td>0.041983</td>\n      <td>0.007242</td>\n      <td>1.000000</td>\n      <td>5</td>\n      <td>{'model__C': 1.0, 'model__degree': 5}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42.699494</td>\n      <td>0.753821</td>\n      <td>0.042960</td>\n      <td>0.006764</td>\n      <td>1.818182</td>\n      <td>3</td>\n      <td>{'model__C': 1.8181818181818183, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42.548427</td>\n      <td>1.089397</td>\n      <td>0.041495</td>\n      <td>0.008384</td>\n      <td>1.818182</td>\n      <td>4</td>\n      <td>{'model__C': 1.8181818181818183, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>43.525415</td>\n      <td>1.487601</td>\n      <td>0.041497</td>\n      <td>0.011311</td>\n      <td>1.818182</td>\n      <td>5</td>\n      <td>{'model__C': 1.8181818181818183, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>43.673092</td>\n      <td>0.788402</td>\n      <td>0.040031</td>\n      <td>0.008678</td>\n      <td>2.636364</td>\n      <td>3</td>\n      <td>{'model__C': 2.6363636363636367, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>42.791194</td>\n      <td>0.659240</td>\n      <td>0.039543</td>\n      <td>0.008720</td>\n      <td>2.636364</td>\n      <td>4</td>\n      <td>{'model__C': 2.6363636363636367, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>42.376492</td>\n      <td>0.681954</td>\n      <td>0.043936</td>\n      <td>0.010651</td>\n      <td>2.636364</td>\n      <td>5</td>\n      <td>{'model__C': 2.6363636363636367, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41.863063</td>\n      <td>0.986847</td>\n      <td>0.041007</td>\n      <td>0.009365</td>\n      <td>3.454545</td>\n      <td>3</td>\n      <td>{'model__C': 3.4545454545454546, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>41.422403</td>\n      <td>0.720028</td>\n      <td>0.040518</td>\n      <td>0.009453</td>\n      <td>3.454545</td>\n      <td>4</td>\n      <td>{'model__C': 3.4545454545454546, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>41.632775</td>\n      <td>0.731734</td>\n      <td>0.041007</td>\n      <td>0.009364</td>\n      <td>3.454545</td>\n      <td>5</td>\n      <td>{'model__C': 3.4545454545454546, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>43.627658</td>\n      <td>2.362819</td>\n      <td>0.040749</td>\n      <td>0.013978</td>\n      <td>4.272727</td>\n      <td>3</td>\n      <td>{'model__C': 4.272727272727273, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>42.035512</td>\n      <td>0.896538</td>\n      <td>0.039542</td>\n      <td>0.008718</td>\n      <td>4.272727</td>\n      <td>4</td>\n      <td>{'model__C': 4.272727272727273, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>42.197584</td>\n      <td>0.607116</td>\n      <td>0.039542</td>\n      <td>0.007796</td>\n      <td>4.272727</td>\n      <td>5</td>\n      <td>{'model__C': 4.272727272727273, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>42.406830</td>\n      <td>0.654658</td>\n      <td>0.038565</td>\n      <td>0.007795</td>\n      <td>5.090909</td>\n      <td>3</td>\n      <td>{'model__C': 5.090909090909091, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>42.321373</td>\n      <td>0.867689</td>\n      <td>0.038566</td>\n      <td>0.008719</td>\n      <td>5.090909</td>\n      <td>4</td>\n      <td>{'model__C': 5.090909090909091, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>42.192731</td>\n      <td>0.702864</td>\n      <td>0.041495</td>\n      <td>0.007419</td>\n      <td>5.090909</td>\n      <td>5</td>\n      <td>{'model__C': 5.090909090909091, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>42.156578</td>\n      <td>0.776284</td>\n      <td>0.038565</td>\n      <td>0.008719</td>\n      <td>5.909091</td>\n      <td>3</td>\n      <td>{'model__C': 5.909090909090909, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>42.092002</td>\n      <td>0.711634</td>\n      <td>0.040519</td>\n      <td>0.007672</td>\n      <td>5.909091</td>\n      <td>4</td>\n      <td>{'model__C': 5.909090909090909, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>42.968819</td>\n      <td>1.145943</td>\n      <td>0.046096</td>\n      <td>0.016727</td>\n      <td>5.909091</td>\n      <td>5</td>\n      <td>{'model__C': 5.909090909090909, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>43.651498</td>\n      <td>2.121176</td>\n      <td>0.042959</td>\n      <td>0.010332</td>\n      <td>6.727273</td>\n      <td>3</td>\n      <td>{'model__C': 6.7272727272727275, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>41.907015</td>\n      <td>0.744578</td>\n      <td>0.040030</td>\n      <td>0.008678</td>\n      <td>6.727273</td>\n      <td>4</td>\n      <td>{'model__C': 6.7272727272727275, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>42.171835</td>\n      <td>0.710066</td>\n      <td>0.040030</td>\n      <td>0.010286</td>\n      <td>6.727273</td>\n      <td>5</td>\n      <td>{'model__C': 6.7272727272727275, 'model__degre...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>42.157184</td>\n      <td>0.661962</td>\n      <td>0.040028</td>\n      <td>0.009513</td>\n      <td>7.545455</td>\n      <td>3</td>\n      <td>{'model__C': 7.545454545454546, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>41.867960</td>\n      <td>0.741843</td>\n      <td>0.041983</td>\n      <td>0.008227</td>\n      <td>7.545455</td>\n      <td>4</td>\n      <td>{'model__C': 7.545454545454546, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>41.732363</td>\n      <td>0.736960</td>\n      <td>0.041982</td>\n      <td>0.009106</td>\n      <td>7.545455</td>\n      <td>5</td>\n      <td>{'model__C': 7.545454545454546, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>43.563962</td>\n      <td>2.274593</td>\n      <td>0.046864</td>\n      <td>0.031966</td>\n      <td>8.363636</td>\n      <td>3</td>\n      <td>{'model__C': 8.363636363636363, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>42.305956</td>\n      <td>0.871946</td>\n      <td>0.042960</td>\n      <td>0.008732</td>\n      <td>8.363636</td>\n      <td>4</td>\n      <td>{'model__C': 8.363636363636363, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>42.364049</td>\n      <td>0.874619</td>\n      <td>0.039542</td>\n      <td>0.007795</td>\n      <td>8.363636</td>\n      <td>5</td>\n      <td>{'model__C': 8.363636363636363, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>42.622309</td>\n      <td>1.160567</td>\n      <td>0.041007</td>\n      <td>0.008511</td>\n      <td>9.181818</td>\n      <td>3</td>\n      <td>{'model__C': 9.181818181818182, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>42.938620</td>\n      <td>1.340953</td>\n      <td>0.041494</td>\n      <td>0.008384</td>\n      <td>9.181818</td>\n      <td>4</td>\n      <td>{'model__C': 9.181818181818182, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>42.626194</td>\n      <td>0.601804</td>\n      <td>0.038567</td>\n      <td>0.008721</td>\n      <td>9.181818</td>\n      <td>5</td>\n      <td>{'model__C': 9.181818181818182, 'model__degree...</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>42.393827</td>\n      <td>0.759404</td>\n      <td>0.041494</td>\n      <td>0.009250</td>\n      <td>10.000000</td>\n      <td>3</td>\n      <td>{'model__C': 10.0, 'model__degree': 3}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>41.448624</td>\n      <td>1.270370</td>\n      <td>0.040030</td>\n      <td>0.007749</td>\n      <td>10.000000</td>\n      <td>4</td>\n      <td>{'model__C': 10.0, 'model__degree': 4}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>42.248842</td>\n      <td>3.279531</td>\n      <td>0.039543</td>\n      <td>0.010320</td>\n      <td>10.000000</td>\n      <td>5</td>\n      <td>{'model__C': 10.0, 'model__degree': 5}</td>\n      <td>0.577764</td>\n      <td>0.586905</td>\n      <td>0.577764</td>\n      <td>...</td>\n      <td>0.734087</td>\n      <td>0.730879</td>\n      <td>0.73511</td>\n      <td>0.733672</td>\n      <td>0.734351</td>\n      <td>0.734252</td>\n      <td>0.731807</td>\n      <td>0.733342</td>\n      <td>0.733438</td>\n      <td>0.00124</td>\n    </tr>\n  </tbody>\n</table>\n<p>36 rows  214 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_gs_cv = pd.DataFrame(model_4_gs.cv_results_)\n",
    "model_4_gs_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model_4_gs_cv.to_pickle('../../data/temp/model_4.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7334280381149567,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x000001C0E0029D90>))])),\n                 ('model', SVC(class_weight={0: 0, 1: 1.4736842105263157}))]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_gs.best_score_, model_4_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model five"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('model', KNeighborsClassifier())],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'model': KNeighborsClassifier(),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'model__algorithm': 'auto',\n 'model__leaf_size': 30,\n 'model__metric': 'minkowski',\n 'model__metric_params': None,\n 'model__n_jobs': None,\n 'model__n_neighbors': 5,\n 'model__p': 2,\n 'model__weights': 'uniform'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('model', KNeighborsClassifier())])\n",
    "model_5.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=8, n_splits=4, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x000002212DF39D90>))])),\n                                       ('model', KNeighborsClassifier())]),\n             n_jobs=-1,\n             param_grid={'model__leaf_size': [30, 45, 100, 250, 500],\n                         'model__n_neighbors': [5, 7, 9, 11]},\n             refit='f1', return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5 = {'model__n_neighbors': list(range(5, 13, 2)),\n",
    "          'model__leaf_size': [30, 45, 100, 250, 500]}\n",
    "\n",
    "model_5_gs = GridSearchCV(estimator=model_5, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid_5,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True)\n",
    "model_5_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       24.505334      4.018202         3.116283        1.122605   \n1       22.937959      3.597796         2.767414        0.859990   \n2       23.490075      4.061072         3.187726        0.962415   \n3       22.905739      3.935650         3.270715        0.948864   \n4       22.936173      3.909475         2.569061        0.903624   \n5       23.464691      3.912794         2.965121        0.923655   \n6       22.649939      3.987537         3.231662        0.985040   \n7       22.448327      4.280280         3.645626        0.961099   \n8       23.334350      4.136685         2.805004        1.174193   \n9       23.424171      4.400454         3.612431        1.219584   \n10      23.382678      4.278214         3.936085        1.348518   \n11      23.750312      4.273243         4.297587        1.751751   \n12      24.843956      4.043078         3.839627        1.225283   \n13      23.903624      3.734200         4.735560        1.474026   \n14      22.996229      3.317044         4.756117        1.789991   \n15      23.611001      4.396328         5.061073        1.733769   \n16      23.732055      3.571320         4.904636        2.167477   \n17      22.691922      3.442202         5.822360        1.564777   \n18      23.112234      4.136678         6.034712        2.176073   \n19      23.534882      3.658080         6.109789        2.033602   \n\n   param_model__leaf_size param_model__n_neighbors  \\\n0                      30                        5   \n1                      30                        7   \n2                      30                        9   \n3                      30                       11   \n4                      45                        5   \n5                      45                        7   \n6                      45                        9   \n7                      45                       11   \n8                     100                        5   \n9                     100                        7   \n10                    100                        9   \n11                    100                       11   \n12                    250                        5   \n13                    250                        7   \n14                    250                        9   \n15                    250                       11   \n16                    500                        5   \n17                    500                        7   \n18                    500                        9   \n19                    500                       11   \n\n                                               params  split0_test_precision  \\\n0   {'model__leaf_size': 30, 'model__n_neighbors': 5}               0.720363   \n1   {'model__leaf_size': 30, 'model__n_neighbors': 7}               0.731288   \n2   {'model__leaf_size': 30, 'model__n_neighbors': 9}               0.738602   \n3   {'model__leaf_size': 30, 'model__n_neighbors':...               0.739062   \n4   {'model__leaf_size': 45, 'model__n_neighbors': 5}               0.725048   \n5   {'model__leaf_size': 45, 'model__n_neighbors': 7}               0.738411   \n6   {'model__leaf_size': 45, 'model__n_neighbors': 9}               0.733173   \n7   {'model__leaf_size': 45, 'model__n_neighbors':...               0.730113   \n8   {'model__leaf_size': 100, 'model__n_neighbors'...               0.735699   \n9   {'model__leaf_size': 100, 'model__n_neighbors'...               0.731876   \n10  {'model__leaf_size': 100, 'model__n_neighbors'...               0.735721   \n11  {'model__leaf_size': 100, 'model__n_neighbors'...               0.756119   \n12  {'model__leaf_size': 250, 'model__n_neighbors'...               0.720246   \n13  {'model__leaf_size': 250, 'model__n_neighbors'...               0.737198   \n14  {'model__leaf_size': 250, 'model__n_neighbors'...               0.748690   \n15  {'model__leaf_size': 250, 'model__n_neighbors'...               0.737405   \n16  {'model__leaf_size': 500, 'model__n_neighbors'...               0.708042   \n17  {'model__leaf_size': 500, 'model__n_neighbors'...               0.735161   \n18  {'model__leaf_size': 500, 'model__n_neighbors'...               0.732926   \n19  {'model__leaf_size': 500, 'model__n_neighbors'...               0.735262   \n\n    split1_test_precision  split2_test_precision  ...  split24_train_f1  \\\n0                0.739038               0.724364  ...          0.811385   \n1                0.725782               0.723163  ...          0.795995   \n2                0.732779               0.727467  ...          0.782845   \n3                0.729795               0.728795  ...          0.778573   \n4                0.715171               0.728227  ...          0.819373   \n5                0.708877               0.739726  ...          0.814149   \n6                0.731347               0.725681  ...          0.770067   \n7                0.714411               0.745153  ...          0.773971   \n8                0.734270               0.710203  ...          0.818753   \n9                0.710932               0.724573  ...          0.780977   \n10               0.723172               0.723908  ...          0.785484   \n11               0.713968               0.727489  ...          0.782484   \n12               0.721576               0.709411  ...          0.816872   \n13               0.729625               0.727098  ...          0.800907   \n14               0.722682               0.723318  ...          0.786951   \n15               0.727981               0.720246  ...          0.779580   \n16               0.717884               0.723681  ...          0.813858   \n17               0.736219               0.703406  ...          0.795401   \n18               0.714192               0.730753  ...          0.786289   \n19               0.731330               0.728784  ...          0.775355   \n\n    split25_train_f1  split26_train_f1  split27_train_f1  split28_train_f1  \\\n0           0.819968          0.817105          0.827670          0.812873   \n1           0.792730          0.794281          0.805782          0.800754   \n2           0.794299          0.783649          0.782116          0.766360   \n3           0.776454          0.775333          0.790763          0.773783   \n4           0.816579          0.818133          0.820368          0.819516   \n5           0.795406          0.806892          0.805782          0.783460   \n6           0.792407          0.791023          0.794240          0.788299   \n7           0.781501          0.779056          0.771430          0.776805   \n8           0.817034          0.816982          0.822768          0.802669   \n9           0.800344          0.796649          0.792948          0.801391   \n10          0.788562          0.773242          0.780275          0.787926   \n11          0.776711          0.775623          0.775223          0.778106   \n12          0.802245          0.825442          0.825523          0.824398   \n13          0.795174          0.808138          0.800697          0.794226   \n14          0.788610          0.785536          0.777722          0.790037   \n15          0.792562          0.774788          0.773821          0.765382   \n16          0.823606          0.825370          0.820584          0.822594   \n17          0.801687          0.800057          0.797319          0.800684   \n18          0.784588          0.785694          0.783989          0.784757   \n19          0.771188          0.761156          0.776250          0.781263   \n\n    split29_train_f1  split30_train_f1  split31_train_f1  mean_train_f1  \\\n0           0.819203          0.813778          0.815865       0.818964   \n1           0.795347          0.792234          0.797187       0.797043   \n2           0.786052          0.788063          0.788386       0.784258   \n3           0.763316          0.777598          0.766807       0.777303   \n4           0.824714          0.822488          0.810747       0.818573   \n5           0.796572          0.799442          0.795719       0.798611   \n6           0.782285          0.781807          0.791074       0.785335   \n7           0.772734          0.767677          0.773384       0.776297   \n8           0.815633          0.800357          0.806377       0.814328   \n9           0.794472          0.795192          0.799800       0.795035   \n10          0.784689          0.786614          0.782802       0.786894   \n11          0.773170          0.771699          0.772624       0.776380   \n12          0.818793          0.834254          0.818952       0.816180   \n13          0.788087          0.797177          0.806252       0.800299   \n14          0.771344          0.783098          0.791217       0.783758   \n15          0.771534          0.771086          0.776319       0.774952   \n16          0.819184          0.816733          0.799302       0.817505   \n17          0.784923          0.799253          0.791985       0.797127   \n18          0.774564          0.778030          0.776833       0.785615   \n19          0.769668          0.783805          0.779410       0.776210   \n\n    std_train_f1  \n0       0.007363  \n1       0.005463  \n2       0.005734  \n3       0.006813  \n4       0.005277  \n5       0.007688  \n6       0.005966  \n7       0.006150  \n8       0.009045  \n9       0.006209  \n10      0.006819  \n11      0.007333  \n12      0.007506  \n13      0.006424  \n14      0.006812  \n15      0.007036  \n16      0.007092  \n17      0.006583  \n18      0.005824  \n19      0.006937  \n\n[20 rows x 214 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__leaf_size</th>\n      <th>param_model__n_neighbors</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>split2_test_precision</th>\n      <th>...</th>\n      <th>split24_train_f1</th>\n      <th>split25_train_f1</th>\n      <th>split26_train_f1</th>\n      <th>split27_train_f1</th>\n      <th>split28_train_f1</th>\n      <th>split29_train_f1</th>\n      <th>split30_train_f1</th>\n      <th>split31_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24.505334</td>\n      <td>4.018202</td>\n      <td>3.116283</td>\n      <td>1.122605</td>\n      <td>30</td>\n      <td>5</td>\n      <td>{'model__leaf_size': 30, 'model__n_neighbors': 5}</td>\n      <td>0.720363</td>\n      <td>0.739038</td>\n      <td>0.724364</td>\n      <td>...</td>\n      <td>0.811385</td>\n      <td>0.819968</td>\n      <td>0.817105</td>\n      <td>0.827670</td>\n      <td>0.812873</td>\n      <td>0.819203</td>\n      <td>0.813778</td>\n      <td>0.815865</td>\n      <td>0.818964</td>\n      <td>0.007363</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.937959</td>\n      <td>3.597796</td>\n      <td>2.767414</td>\n      <td>0.859990</td>\n      <td>30</td>\n      <td>7</td>\n      <td>{'model__leaf_size': 30, 'model__n_neighbors': 7}</td>\n      <td>0.731288</td>\n      <td>0.725782</td>\n      <td>0.723163</td>\n      <td>...</td>\n      <td>0.795995</td>\n      <td>0.792730</td>\n      <td>0.794281</td>\n      <td>0.805782</td>\n      <td>0.800754</td>\n      <td>0.795347</td>\n      <td>0.792234</td>\n      <td>0.797187</td>\n      <td>0.797043</td>\n      <td>0.005463</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23.490075</td>\n      <td>4.061072</td>\n      <td>3.187726</td>\n      <td>0.962415</td>\n      <td>30</td>\n      <td>9</td>\n      <td>{'model__leaf_size': 30, 'model__n_neighbors': 9}</td>\n      <td>0.738602</td>\n      <td>0.732779</td>\n      <td>0.727467</td>\n      <td>...</td>\n      <td>0.782845</td>\n      <td>0.794299</td>\n      <td>0.783649</td>\n      <td>0.782116</td>\n      <td>0.766360</td>\n      <td>0.786052</td>\n      <td>0.788063</td>\n      <td>0.788386</td>\n      <td>0.784258</td>\n      <td>0.005734</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22.905739</td>\n      <td>3.935650</td>\n      <td>3.270715</td>\n      <td>0.948864</td>\n      <td>30</td>\n      <td>11</td>\n      <td>{'model__leaf_size': 30, 'model__n_neighbors':...</td>\n      <td>0.739062</td>\n      <td>0.729795</td>\n      <td>0.728795</td>\n      <td>...</td>\n      <td>0.778573</td>\n      <td>0.776454</td>\n      <td>0.775333</td>\n      <td>0.790763</td>\n      <td>0.773783</td>\n      <td>0.763316</td>\n      <td>0.777598</td>\n      <td>0.766807</td>\n      <td>0.777303</td>\n      <td>0.006813</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22.936173</td>\n      <td>3.909475</td>\n      <td>2.569061</td>\n      <td>0.903624</td>\n      <td>45</td>\n      <td>5</td>\n      <td>{'model__leaf_size': 45, 'model__n_neighbors': 5}</td>\n      <td>0.725048</td>\n      <td>0.715171</td>\n      <td>0.728227</td>\n      <td>...</td>\n      <td>0.819373</td>\n      <td>0.816579</td>\n      <td>0.818133</td>\n      <td>0.820368</td>\n      <td>0.819516</td>\n      <td>0.824714</td>\n      <td>0.822488</td>\n      <td>0.810747</td>\n      <td>0.818573</td>\n      <td>0.005277</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>23.464691</td>\n      <td>3.912794</td>\n      <td>2.965121</td>\n      <td>0.923655</td>\n      <td>45</td>\n      <td>7</td>\n      <td>{'model__leaf_size': 45, 'model__n_neighbors': 7}</td>\n      <td>0.738411</td>\n      <td>0.708877</td>\n      <td>0.739726</td>\n      <td>...</td>\n      <td>0.814149</td>\n      <td>0.795406</td>\n      <td>0.806892</td>\n      <td>0.805782</td>\n      <td>0.783460</td>\n      <td>0.796572</td>\n      <td>0.799442</td>\n      <td>0.795719</td>\n      <td>0.798611</td>\n      <td>0.007688</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22.649939</td>\n      <td>3.987537</td>\n      <td>3.231662</td>\n      <td>0.985040</td>\n      <td>45</td>\n      <td>9</td>\n      <td>{'model__leaf_size': 45, 'model__n_neighbors': 9}</td>\n      <td>0.733173</td>\n      <td>0.731347</td>\n      <td>0.725681</td>\n      <td>...</td>\n      <td>0.770067</td>\n      <td>0.792407</td>\n      <td>0.791023</td>\n      <td>0.794240</td>\n      <td>0.788299</td>\n      <td>0.782285</td>\n      <td>0.781807</td>\n      <td>0.791074</td>\n      <td>0.785335</td>\n      <td>0.005966</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.448327</td>\n      <td>4.280280</td>\n      <td>3.645626</td>\n      <td>0.961099</td>\n      <td>45</td>\n      <td>11</td>\n      <td>{'model__leaf_size': 45, 'model__n_neighbors':...</td>\n      <td>0.730113</td>\n      <td>0.714411</td>\n      <td>0.745153</td>\n      <td>...</td>\n      <td>0.773971</td>\n      <td>0.781501</td>\n      <td>0.779056</td>\n      <td>0.771430</td>\n      <td>0.776805</td>\n      <td>0.772734</td>\n      <td>0.767677</td>\n      <td>0.773384</td>\n      <td>0.776297</td>\n      <td>0.006150</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>23.334350</td>\n      <td>4.136685</td>\n      <td>2.805004</td>\n      <td>1.174193</td>\n      <td>100</td>\n      <td>5</td>\n      <td>{'model__leaf_size': 100, 'model__n_neighbors'...</td>\n      <td>0.735699</td>\n      <td>0.734270</td>\n      <td>0.710203</td>\n      <td>...</td>\n      <td>0.818753</td>\n      <td>0.817034</td>\n      <td>0.816982</td>\n      <td>0.822768</td>\n      <td>0.802669</td>\n      <td>0.815633</td>\n      <td>0.800357</td>\n      <td>0.806377</td>\n      <td>0.814328</td>\n      <td>0.009045</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>23.424171</td>\n      <td>4.400454</td>\n      <td>3.612431</td>\n      <td>1.219584</td>\n      <td>100</td>\n      <td>7</td>\n      <td>{'model__leaf_size': 100, 'model__n_neighbors'...</td>\n      <td>0.731876</td>\n      <td>0.710932</td>\n      <td>0.724573</td>\n      <td>...</td>\n      <td>0.780977</td>\n      <td>0.800344</td>\n      <td>0.796649</td>\n      <td>0.792948</td>\n      <td>0.801391</td>\n      <td>0.794472</td>\n      <td>0.795192</td>\n      <td>0.799800</td>\n      <td>0.795035</td>\n      <td>0.006209</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>23.382678</td>\n      <td>4.278214</td>\n      <td>3.936085</td>\n      <td>1.348518</td>\n      <td>100</td>\n      <td>9</td>\n      <td>{'model__leaf_size': 100, 'model__n_neighbors'...</td>\n      <td>0.735721</td>\n      <td>0.723172</td>\n      <td>0.723908</td>\n      <td>...</td>\n      <td>0.785484</td>\n      <td>0.788562</td>\n      <td>0.773242</td>\n      <td>0.780275</td>\n      <td>0.787926</td>\n      <td>0.784689</td>\n      <td>0.786614</td>\n      <td>0.782802</td>\n      <td>0.786894</td>\n      <td>0.006819</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>23.750312</td>\n      <td>4.273243</td>\n      <td>4.297587</td>\n      <td>1.751751</td>\n      <td>100</td>\n      <td>11</td>\n      <td>{'model__leaf_size': 100, 'model__n_neighbors'...</td>\n      <td>0.756119</td>\n      <td>0.713968</td>\n      <td>0.727489</td>\n      <td>...</td>\n      <td>0.782484</td>\n      <td>0.776711</td>\n      <td>0.775623</td>\n      <td>0.775223</td>\n      <td>0.778106</td>\n      <td>0.773170</td>\n      <td>0.771699</td>\n      <td>0.772624</td>\n      <td>0.776380</td>\n      <td>0.007333</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>24.843956</td>\n      <td>4.043078</td>\n      <td>3.839627</td>\n      <td>1.225283</td>\n      <td>250</td>\n      <td>5</td>\n      <td>{'model__leaf_size': 250, 'model__n_neighbors'...</td>\n      <td>0.720246</td>\n      <td>0.721576</td>\n      <td>0.709411</td>\n      <td>...</td>\n      <td>0.816872</td>\n      <td>0.802245</td>\n      <td>0.825442</td>\n      <td>0.825523</td>\n      <td>0.824398</td>\n      <td>0.818793</td>\n      <td>0.834254</td>\n      <td>0.818952</td>\n      <td>0.816180</td>\n      <td>0.007506</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.903624</td>\n      <td>3.734200</td>\n      <td>4.735560</td>\n      <td>1.474026</td>\n      <td>250</td>\n      <td>7</td>\n      <td>{'model__leaf_size': 250, 'model__n_neighbors'...</td>\n      <td>0.737198</td>\n      <td>0.729625</td>\n      <td>0.727098</td>\n      <td>...</td>\n      <td>0.800907</td>\n      <td>0.795174</td>\n      <td>0.808138</td>\n      <td>0.800697</td>\n      <td>0.794226</td>\n      <td>0.788087</td>\n      <td>0.797177</td>\n      <td>0.806252</td>\n      <td>0.800299</td>\n      <td>0.006424</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>22.996229</td>\n      <td>3.317044</td>\n      <td>4.756117</td>\n      <td>1.789991</td>\n      <td>250</td>\n      <td>9</td>\n      <td>{'model__leaf_size': 250, 'model__n_neighbors'...</td>\n      <td>0.748690</td>\n      <td>0.722682</td>\n      <td>0.723318</td>\n      <td>...</td>\n      <td>0.786951</td>\n      <td>0.788610</td>\n      <td>0.785536</td>\n      <td>0.777722</td>\n      <td>0.790037</td>\n      <td>0.771344</td>\n      <td>0.783098</td>\n      <td>0.791217</td>\n      <td>0.783758</td>\n      <td>0.006812</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>23.611001</td>\n      <td>4.396328</td>\n      <td>5.061073</td>\n      <td>1.733769</td>\n      <td>250</td>\n      <td>11</td>\n      <td>{'model__leaf_size': 250, 'model__n_neighbors'...</td>\n      <td>0.737405</td>\n      <td>0.727981</td>\n      <td>0.720246</td>\n      <td>...</td>\n      <td>0.779580</td>\n      <td>0.792562</td>\n      <td>0.774788</td>\n      <td>0.773821</td>\n      <td>0.765382</td>\n      <td>0.771534</td>\n      <td>0.771086</td>\n      <td>0.776319</td>\n      <td>0.774952</td>\n      <td>0.007036</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>23.732055</td>\n      <td>3.571320</td>\n      <td>4.904636</td>\n      <td>2.167477</td>\n      <td>500</td>\n      <td>5</td>\n      <td>{'model__leaf_size': 500, 'model__n_neighbors'...</td>\n      <td>0.708042</td>\n      <td>0.717884</td>\n      <td>0.723681</td>\n      <td>...</td>\n      <td>0.813858</td>\n      <td>0.823606</td>\n      <td>0.825370</td>\n      <td>0.820584</td>\n      <td>0.822594</td>\n      <td>0.819184</td>\n      <td>0.816733</td>\n      <td>0.799302</td>\n      <td>0.817505</td>\n      <td>0.007092</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>22.691922</td>\n      <td>3.442202</td>\n      <td>5.822360</td>\n      <td>1.564777</td>\n      <td>500</td>\n      <td>7</td>\n      <td>{'model__leaf_size': 500, 'model__n_neighbors'...</td>\n      <td>0.735161</td>\n      <td>0.736219</td>\n      <td>0.703406</td>\n      <td>...</td>\n      <td>0.795401</td>\n      <td>0.801687</td>\n      <td>0.800057</td>\n      <td>0.797319</td>\n      <td>0.800684</td>\n      <td>0.784923</td>\n      <td>0.799253</td>\n      <td>0.791985</td>\n      <td>0.797127</td>\n      <td>0.006583</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>23.112234</td>\n      <td>4.136678</td>\n      <td>6.034712</td>\n      <td>2.176073</td>\n      <td>500</td>\n      <td>9</td>\n      <td>{'model__leaf_size': 500, 'model__n_neighbors'...</td>\n      <td>0.732926</td>\n      <td>0.714192</td>\n      <td>0.730753</td>\n      <td>...</td>\n      <td>0.786289</td>\n      <td>0.784588</td>\n      <td>0.785694</td>\n      <td>0.783989</td>\n      <td>0.784757</td>\n      <td>0.774564</td>\n      <td>0.778030</td>\n      <td>0.776833</td>\n      <td>0.785615</td>\n      <td>0.005824</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>23.534882</td>\n      <td>3.658080</td>\n      <td>6.109789</td>\n      <td>2.033602</td>\n      <td>500</td>\n      <td>11</td>\n      <td>{'model__leaf_size': 500, 'model__n_neighbors'...</td>\n      <td>0.735262</td>\n      <td>0.731330</td>\n      <td>0.728784</td>\n      <td>...</td>\n      <td>0.775355</td>\n      <td>0.771188</td>\n      <td>0.761156</td>\n      <td>0.776250</td>\n      <td>0.781263</td>\n      <td>0.769668</td>\n      <td>0.783805</td>\n      <td>0.779410</td>\n      <td>0.776210</td>\n      <td>0.006937</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows  214 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_gs_cv = pd.DataFrame(model_5_gs.cv_results_)\n",
    "model_5_gs_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_5_gs_cv.to_pickle('../../data/temp/model_5.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.729442199230999,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x000002212DF39D90>))])),\n                 ('model', KNeighborsClassifier())]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_gs.best_score_, model_5_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model six"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('model', DecisionTreeClassifier())],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'model': DecisionTreeClassifier(),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'gini',\n 'model__max_depth': None,\n 'model__max_features': None,\n 'model__max_leaf_nodes': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_impurity_split': None,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__random_state': None,\n 'model__splitter': 'best'}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('model', DecisionTreeClassifier())])\n",
    "model_6.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=8, n_splits=4, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n                                       ('model', DecisionTreeClassifier())]),\n             n_jobs=-1,\n             param_grid={'model__max_depth': [12, 18, 24, 32],\n                         'model__min_samples_leaf': [25, 45, 65],\n                         'model__min_samples_split': [30, 40, 50, 100]},\n             refit='f1', return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6 = {'model__max_depth': [12, 18, 24, 32],\n",
    "          'model__min_samples_split': [30, 40, 50, 100],\n",
    "          'model__min_samples_leaf': [25, 45, 65]}\n",
    "\n",
    "model_6_gs = GridSearchCV(estimator=model_6, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid_6,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True)\n",
    "model_6_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       22.824216      4.293556         0.046863        0.018728   \n1       22.782232      3.800916         0.043936        0.017655   \n2       22.636759      3.860258         0.047841        0.019107   \n3       22.506419      3.543702         0.046865        0.019132   \n4       23.002885      3.271788         0.049793        0.018906   \n5       22.367291      3.771926         0.045401        0.021518   \n6       22.590158      3.904334         0.043447        0.016904   \n7       22.426847      3.799127         0.042472        0.017567   \n8       22.503002      3.529122         0.041007        0.021656   \n9       22.814939      3.710902         0.035637        0.011206   \n10      22.044125      3.784975         0.044423        0.017071   \n11      22.427337      4.067506         0.045399        0.019666   \n12      22.543605      2.882263         0.044954        0.022065   \n13      22.343041      3.493467         0.052234        0.019373   \n14      22.614305      3.455855         0.043447        0.019811   \n15      22.665560      4.221708         0.049305        0.019176   \n16      22.201316      3.953323         0.043935        0.016769   \n17      22.439051      4.079740         0.045888        0.017870   \n18      22.441004      3.756601         0.044423        0.016618   \n19      22.276493      3.767305         0.049305        0.017943   \n20      21.999702      3.997806         0.043936        0.017217   \n21      22.387307      3.221220         0.045400        0.019666   \n22      22.425872      3.747155         0.045400        0.021518   \n23      22.120813      3.743303         0.047352        0.019324   \n24      22.022046      3.208034         0.045888        0.021008   \n25      22.562067      3.439203         0.046865        0.018318   \n26      22.681671      3.605672         0.044912        0.017356   \n27      22.384378      3.229668         0.045887        0.022069   \n28      22.490309      4.138474         0.043936        0.017655   \n29      22.349718      3.203864         0.050282        0.024617   \n30      22.705951      3.287665         0.047353        0.018518   \n31      22.345811      2.793161         0.044425        0.018774   \n32      22.405531      3.414206         0.042959        0.017897   \n33      22.270147      3.869660         0.048816        0.019817   \n34      22.509347      3.156899         0.043936        0.016769   \n35      17.444134      1.225269         0.033684        0.005672   \n36      16.922285      0.178975         0.034171        0.006097   \n37      16.879326      0.177251         0.033684        0.005672   \n38      17.214696      0.217474         0.033196        0.005167   \n39      18.189120      1.214581         0.035148        0.007811   \n40      17.129755      0.177034         0.033196        0.005169   \n41      17.226900      0.316855         0.034661        0.009352   \n42      16.995998      0.176347         0.036127        0.010655   \n43      17.221531      0.182465         0.035637        0.012494   \n44      17.625734      0.911352         0.035147        0.006764   \n45      17.014060      0.190006         0.031243        0.003905   \n46      16.935953      0.136915         0.033683        0.005671   \n47      16.797317      0.570532         0.032217        0.005438   \n\n   param_model__max_depth param_model__min_samples_leaf  \\\n0                      12                            25   \n1                      12                            25   \n2                      12                            25   \n3                      12                            25   \n4                      12                            45   \n5                      12                            45   \n6                      12                            45   \n7                      12                            45   \n8                      12                            65   \n9                      12                            65   \n10                     12                            65   \n11                     12                            65   \n12                     18                            25   \n13                     18                            25   \n14                     18                            25   \n15                     18                            25   \n16                     18                            45   \n17                     18                            45   \n18                     18                            45   \n19                     18                            45   \n20                     18                            65   \n21                     18                            65   \n22                     18                            65   \n23                     18                            65   \n24                     24                            25   \n25                     24                            25   \n26                     24                            25   \n27                     24                            25   \n28                     24                            45   \n29                     24                            45   \n30                     24                            45   \n31                     24                            45   \n32                     24                            65   \n33                     24                            65   \n34                     24                            65   \n35                     24                            65   \n36                     32                            25   \n37                     32                            25   \n38                     32                            25   \n39                     32                            25   \n40                     32                            45   \n41                     32                            45   \n42                     32                            45   \n43                     32                            45   \n44                     32                            65   \n45                     32                            65   \n46                     32                            65   \n47                     32                            65   \n\n   param_model__min_samples_split  \\\n0                              30   \n1                              40   \n2                              50   \n3                             100   \n4                              30   \n5                              40   \n6                              50   \n7                             100   \n8                              30   \n9                              40   \n10                             50   \n11                            100   \n12                             30   \n13                             40   \n14                             50   \n15                            100   \n16                             30   \n17                             40   \n18                             50   \n19                            100   \n20                             30   \n21                             40   \n22                             50   \n23                            100   \n24                             30   \n25                             40   \n26                             50   \n27                            100   \n28                             30   \n29                             40   \n30                             50   \n31                            100   \n32                             30   \n33                             40   \n34                             50   \n35                            100   \n36                             30   \n37                             40   \n38                             50   \n39                            100   \n40                             30   \n41                             40   \n42                             50   \n43                            100   \n44                             30   \n45                             40   \n46                             50   \n47                            100   \n\n                                               params  split0_test_precision  \\\n0   {'model__max_depth': 12, 'model__min_samples_l...               0.882241   \n1   {'model__max_depth': 12, 'model__min_samples_l...               0.882660   \n2   {'model__max_depth': 12, 'model__min_samples_l...               0.884020   \n3   {'model__max_depth': 12, 'model__min_samples_l...               0.866038   \n4   {'model__max_depth': 12, 'model__min_samples_l...               0.862267   \n5   {'model__max_depth': 12, 'model__min_samples_l...               0.862267   \n6   {'model__max_depth': 12, 'model__min_samples_l...               0.860509   \n7   {'model__max_depth': 12, 'model__min_samples_l...               0.862981   \n8   {'model__max_depth': 12, 'model__min_samples_l...               0.871072   \n9   {'model__max_depth': 12, 'model__min_samples_l...               0.872372   \n10  {'model__max_depth': 12, 'model__min_samples_l...               0.872372   \n11  {'model__max_depth': 12, 'model__min_samples_l...               0.873352   \n12  {'model__max_depth': 18, 'model__min_samples_l...               0.921519   \n13  {'model__max_depth': 18, 'model__min_samples_l...               0.922774   \n14  {'model__max_depth': 18, 'model__min_samples_l...               0.921755   \n15  {'model__max_depth': 18, 'model__min_samples_l...               0.908099   \n16  {'model__max_depth': 18, 'model__min_samples_l...               0.886518   \n17  {'model__max_depth': 18, 'model__min_samples_l...               0.888131   \n18  {'model__max_depth': 18, 'model__min_samples_l...               0.886099   \n19  {'model__max_depth': 18, 'model__min_samples_l...               0.891960   \n20  {'model__max_depth': 18, 'model__min_samples_l...               0.882215   \n21  {'model__max_depth': 18, 'model__min_samples_l...               0.882215   \n22  {'model__max_depth': 18, 'model__min_samples_l...               0.882215   \n23  {'model__max_depth': 18, 'model__min_samples_l...               0.882215   \n24  {'model__max_depth': 24, 'model__min_samples_l...               0.913252   \n25  {'model__max_depth': 24, 'model__min_samples_l...               0.912655   \n26  {'model__max_depth': 24, 'model__min_samples_l...               0.914267   \n27  {'model__max_depth': 24, 'model__min_samples_l...               0.891904   \n28  {'model__max_depth': 24, 'model__min_samples_l...               0.878914   \n29  {'model__max_depth': 24, 'model__min_samples_l...               0.875571   \n30  {'model__max_depth': 24, 'model__min_samples_l...               0.877377   \n31  {'model__max_depth': 24, 'model__min_samples_l...               0.880380   \n32  {'model__max_depth': 24, 'model__min_samples_l...               0.871847   \n33  {'model__max_depth': 24, 'model__min_samples_l...               0.873030   \n34  {'model__max_depth': 24, 'model__min_samples_l...               0.871847   \n35  {'model__max_depth': 24, 'model__min_samples_l...               0.873030   \n36  {'model__max_depth': 32, 'model__min_samples_l...               0.908255   \n37  {'model__max_depth': 32, 'model__min_samples_l...               0.908701   \n38  {'model__max_depth': 32, 'model__min_samples_l...               0.909836   \n39  {'model__max_depth': 32, 'model__min_samples_l...               0.888410   \n40  {'model__max_depth': 32, 'model__min_samples_l...               0.870227   \n41  {'model__max_depth': 32, 'model__min_samples_l...               0.873167   \n42  {'model__max_depth': 32, 'model__min_samples_l...               0.873088   \n43  {'model__max_depth': 32, 'model__min_samples_l...               0.877323   \n44  {'model__max_depth': 32, 'model__min_samples_l...               0.869488   \n45  {'model__max_depth': 32, 'model__min_samples_l...               0.868316   \n46  {'model__max_depth': 32, 'model__min_samples_l...               0.869488   \n47  {'model__max_depth': 32, 'model__min_samples_l...               0.869488   \n\n    split1_test_precision  ...  split24_train_f1  split25_train_f1  \\\n0                0.883448  ...          0.833994          0.808883   \n1                0.884598  ...          0.833751          0.808441   \n2                0.883651  ...          0.833680          0.808441   \n3                0.872711  ...          0.826403          0.794667   \n4                0.873540  ...          0.820978          0.790974   \n5                0.874713  ...          0.820978          0.790696   \n6                0.875835  ...          0.820978          0.790893   \n7                0.876703  ...          0.819359          0.787834   \n8                0.856945  ...          0.816400          0.809913   \n9                0.857044  ...          0.816400          0.809913   \n10               0.857044  ...          0.816400          0.809913   \n11               0.857242  ...          0.816400          0.809913   \n12               0.905130  ...          0.901173          0.864709   \n13               0.905182  ...          0.902610          0.864837   \n14               0.908207  ...          0.901056          0.864183   \n15               0.889818  ...          0.887559          0.850618   \n16               0.882927  ...          0.884264          0.847256   \n17               0.881916  ...          0.884303          0.847225   \n18               0.880912  ...          0.883131          0.847577   \n19               0.881916  ...          0.882853          0.844954   \n20               0.866200  ...          0.862757          0.856041   \n21               0.865296  ...          0.862757          0.856389   \n22               0.866302  ...          0.862757          0.856389   \n23               0.866200  ...          0.862757          0.856399   \n24               0.920423  ...          0.913278          0.906904   \n25               0.919991  ...          0.913020          0.906904   \n26               0.920069  ...          0.913253          0.907036   \n27               0.893023  ...          0.897507          0.888345   \n28               0.884785  ...          0.886596          0.881620   \n29               0.887063  ...          0.888905          0.881274   \n30               0.886526  ...          0.888786          0.881355   \n31               0.886105  ...          0.884932          0.879495   \n32               0.872911  ...          0.866205          0.869746   \n33               0.873019  ...          0.866205          0.869171   \n34               0.873019  ...          0.866205          0.868705   \n35               0.873019  ...          0.865013          0.869334   \n36               0.921143  ...          0.917527          0.923265   \n37               0.922514  ...          0.917812          0.922700   \n38               0.921143  ...          0.917512          0.922600   \n39               0.891118  ...          0.901106          0.903330   \n40               0.882842  ...          0.890294          0.892983   \n41               0.885499  ...          0.889940          0.892625   \n42               0.885499  ...          0.889940          0.892955   \n43               0.885499  ...          0.885911          0.890013   \n44               0.872739  ...          0.866205          0.869747   \n45               0.873212  ...          0.866202          0.870087   \n46               0.872739  ...          0.866205          0.869747   \n47               0.872275  ...          0.866205          0.870199   \n\n    split26_train_f1  split27_train_f1  split28_train_f1  split29_train_f1  \\\n0           0.831914          0.823288          0.831128          0.817174   \n1           0.838091          0.822188          0.831140          0.817174   \n2           0.831914          0.822238          0.830933          0.817174   \n3           0.823088          0.811806          0.818763          0.808269   \n4           0.827842          0.807309          0.828526          0.803279   \n5           0.827881          0.806918          0.828526          0.803279   \n6           0.827839          0.807309          0.828526          0.803279   \n7           0.827266          0.806759          0.827176          0.802059   \n8           0.830847          0.807055          0.827835          0.788422   \n9           0.831422          0.807055          0.827783          0.788422   \n10          0.830847          0.806977          0.827783          0.788455   \n11          0.831010          0.807055          0.827866          0.788422   \n12          0.887544          0.875173          0.889674          0.861784   \n13          0.887427          0.875173          0.889724          0.861897   \n14          0.887410          0.875023          0.889633          0.862355   \n15          0.872152          0.860879          0.872803          0.849054   \n16          0.872731          0.853216          0.877608          0.843249   \n17          0.872511          0.853478          0.877509          0.843036   \n18          0.872980          0.853599          0.877550          0.843446   \n19          0.871960          0.852944          0.875982          0.840319   \n20          0.854206          0.848809          0.860961          0.837465   \n21          0.854206          0.849477          0.860919          0.837465   \n22          0.853642          0.849466          0.860919          0.837465   \n23          0.854143          0.849477          0.860961          0.837465   \n24          0.909051          0.913083          0.912302          0.914876   \n25          0.908591          0.912431          0.912276          0.914771   \n26          0.908505          0.913091          0.912063          0.915120   \n27          0.892115          0.893608          0.892755          0.895974   \n28          0.885708          0.883787          0.888625          0.886642   \n29          0.885593          0.883589          0.888553          0.886642   \n30          0.885770          0.882511          0.888418          0.886332   \n31          0.884746          0.882850          0.887182          0.883258   \n32          0.861467          0.850984          0.872865          0.859196   \n33          0.861971          0.850984          0.872874          0.858819   \n34          0.861436          0.850975          0.872806          0.858861   \n35          0.861436          0.850975          0.872806          0.858767   \n36          0.916570          0.921309          0.917249          0.923271   \n37          0.917160          0.921413          0.917309          0.923271   \n38          0.917226          0.921221          0.917319          0.923254   \n39          0.899210          0.898180          0.897553          0.901529   \n40          0.890072          0.886390          0.892707          0.893218   \n41          0.890527          0.886936          0.892700          0.893305   \n42          0.890072          0.886596          0.892762          0.892925   \n43          0.889634          0.885725          0.890383          0.889931   \n44          0.864637          0.850984          0.872806          0.867310   \n45          0.864164          0.850975          0.872806          0.867207   \n46          0.864164          0.850584          0.872806          0.867207   \n47          0.864164          0.850984          0.872806          0.867207   \n\n    split30_train_f1  split31_train_f1  mean_train_f1  std_train_f1  \n0           0.855585          0.833802       0.833146      0.015347  \n1           0.855585          0.833802       0.833291      0.015431  \n2           0.855585          0.833802       0.833071      0.015402  \n3           0.841069          0.823600       0.822376      0.015233  \n4           0.829492          0.834042       0.821073      0.016280  \n5           0.829492          0.833869       0.821113      0.016213  \n6           0.829626          0.834042       0.821008      0.016365  \n7           0.829159          0.832331       0.820028      0.016345  \n8           0.824742          0.831279       0.816265      0.013093  \n9           0.824729          0.831279       0.816274      0.013009  \n10          0.824806          0.831117       0.816285      0.013091  \n11          0.825141          0.831279       0.816255      0.013049  \n12          0.898823          0.906114       0.890306      0.014709  \n13          0.898870          0.906541       0.890303      0.014733  \n14          0.898823          0.906672       0.890330      0.014695  \n15          0.880255          0.889573       0.873801      0.012915  \n16          0.872664          0.882483       0.869556      0.012348  \n17          0.873328          0.882483       0.869567      0.012396  \n18          0.872923          0.882483       0.869605      0.012295  \n19          0.872106          0.879765       0.868358      0.012377  \n20          0.858113          0.862473       0.854604      0.006118  \n21          0.858350          0.862104       0.854571      0.006062  \n22          0.858350          0.862473       0.854647      0.006203  \n23          0.858350          0.862104       0.854722      0.006119  \n24          0.923966          0.916056       0.914251      0.006004  \n25          0.924482          0.916186       0.914208      0.006029  \n26          0.924005          0.915961       0.914079      0.005958  \n27          0.901939          0.896095       0.894375      0.005150  \n28          0.892216          0.885733       0.886749      0.003843  \n29          0.892336          0.887280       0.886889      0.003873  \n30          0.892134          0.885733       0.886771      0.003876  \n31          0.891435          0.884391       0.885372      0.003760  \n32          0.866323          0.862648       0.864073      0.004628  \n33          0.866108          0.862648       0.864059      0.004658  \n34          0.866108          0.862648       0.863981      0.004490  \n35          0.866323          0.864809       0.864085      0.004636  \n36          0.928322          0.916353       0.920859      0.004020  \n37          0.928551          0.916676       0.920752      0.003964  \n38          0.928058          0.915894       0.920740      0.003918  \n39          0.905446          0.897383       0.899617      0.003883  \n40          0.894093          0.886165       0.890548      0.003229  \n41          0.893619          0.886165       0.890602      0.003139  \n42          0.894386          0.886165       0.890398      0.003267  \n43          0.893871          0.883757       0.888865      0.003071  \n44          0.867019          0.863052       0.865177      0.004605  \n45          0.866928          0.862648       0.865075      0.004749  \n46          0.866683          0.863052       0.865146      0.004695  \n47          0.866643          0.863158       0.865145      0.004764  \n\n[48 rows x 215 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__max_depth</th>\n      <th>param_model__min_samples_leaf</th>\n      <th>param_model__min_samples_split</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>...</th>\n      <th>split24_train_f1</th>\n      <th>split25_train_f1</th>\n      <th>split26_train_f1</th>\n      <th>split27_train_f1</th>\n      <th>split28_train_f1</th>\n      <th>split29_train_f1</th>\n      <th>split30_train_f1</th>\n      <th>split31_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.824216</td>\n      <td>4.293556</td>\n      <td>0.046863</td>\n      <td>0.018728</td>\n      <td>12</td>\n      <td>25</td>\n      <td>30</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.882241</td>\n      <td>0.883448</td>\n      <td>...</td>\n      <td>0.833994</td>\n      <td>0.808883</td>\n      <td>0.831914</td>\n      <td>0.823288</td>\n      <td>0.831128</td>\n      <td>0.817174</td>\n      <td>0.855585</td>\n      <td>0.833802</td>\n      <td>0.833146</td>\n      <td>0.015347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.782232</td>\n      <td>3.800916</td>\n      <td>0.043936</td>\n      <td>0.017655</td>\n      <td>12</td>\n      <td>25</td>\n      <td>40</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.882660</td>\n      <td>0.884598</td>\n      <td>...</td>\n      <td>0.833751</td>\n      <td>0.808441</td>\n      <td>0.838091</td>\n      <td>0.822188</td>\n      <td>0.831140</td>\n      <td>0.817174</td>\n      <td>0.855585</td>\n      <td>0.833802</td>\n      <td>0.833291</td>\n      <td>0.015431</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22.636759</td>\n      <td>3.860258</td>\n      <td>0.047841</td>\n      <td>0.019107</td>\n      <td>12</td>\n      <td>25</td>\n      <td>50</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.884020</td>\n      <td>0.883651</td>\n      <td>...</td>\n      <td>0.833680</td>\n      <td>0.808441</td>\n      <td>0.831914</td>\n      <td>0.822238</td>\n      <td>0.830933</td>\n      <td>0.817174</td>\n      <td>0.855585</td>\n      <td>0.833802</td>\n      <td>0.833071</td>\n      <td>0.015402</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22.506419</td>\n      <td>3.543702</td>\n      <td>0.046865</td>\n      <td>0.019132</td>\n      <td>12</td>\n      <td>25</td>\n      <td>100</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.866038</td>\n      <td>0.872711</td>\n      <td>...</td>\n      <td>0.826403</td>\n      <td>0.794667</td>\n      <td>0.823088</td>\n      <td>0.811806</td>\n      <td>0.818763</td>\n      <td>0.808269</td>\n      <td>0.841069</td>\n      <td>0.823600</td>\n      <td>0.822376</td>\n      <td>0.015233</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23.002885</td>\n      <td>3.271788</td>\n      <td>0.049793</td>\n      <td>0.018906</td>\n      <td>12</td>\n      <td>45</td>\n      <td>30</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.862267</td>\n      <td>0.873540</td>\n      <td>...</td>\n      <td>0.820978</td>\n      <td>0.790974</td>\n      <td>0.827842</td>\n      <td>0.807309</td>\n      <td>0.828526</td>\n      <td>0.803279</td>\n      <td>0.829492</td>\n      <td>0.834042</td>\n      <td>0.821073</td>\n      <td>0.016280</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>22.367291</td>\n      <td>3.771926</td>\n      <td>0.045401</td>\n      <td>0.021518</td>\n      <td>12</td>\n      <td>45</td>\n      <td>40</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.862267</td>\n      <td>0.874713</td>\n      <td>...</td>\n      <td>0.820978</td>\n      <td>0.790696</td>\n      <td>0.827881</td>\n      <td>0.806918</td>\n      <td>0.828526</td>\n      <td>0.803279</td>\n      <td>0.829492</td>\n      <td>0.833869</td>\n      <td>0.821113</td>\n      <td>0.016213</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22.590158</td>\n      <td>3.904334</td>\n      <td>0.043447</td>\n      <td>0.016904</td>\n      <td>12</td>\n      <td>45</td>\n      <td>50</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.860509</td>\n      <td>0.875835</td>\n      <td>...</td>\n      <td>0.820978</td>\n      <td>0.790893</td>\n      <td>0.827839</td>\n      <td>0.807309</td>\n      <td>0.828526</td>\n      <td>0.803279</td>\n      <td>0.829626</td>\n      <td>0.834042</td>\n      <td>0.821008</td>\n      <td>0.016365</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.426847</td>\n      <td>3.799127</td>\n      <td>0.042472</td>\n      <td>0.017567</td>\n      <td>12</td>\n      <td>45</td>\n      <td>100</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.862981</td>\n      <td>0.876703</td>\n      <td>...</td>\n      <td>0.819359</td>\n      <td>0.787834</td>\n      <td>0.827266</td>\n      <td>0.806759</td>\n      <td>0.827176</td>\n      <td>0.802059</td>\n      <td>0.829159</td>\n      <td>0.832331</td>\n      <td>0.820028</td>\n      <td>0.016345</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>22.503002</td>\n      <td>3.529122</td>\n      <td>0.041007</td>\n      <td>0.021656</td>\n      <td>12</td>\n      <td>65</td>\n      <td>30</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.871072</td>\n      <td>0.856945</td>\n      <td>...</td>\n      <td>0.816400</td>\n      <td>0.809913</td>\n      <td>0.830847</td>\n      <td>0.807055</td>\n      <td>0.827835</td>\n      <td>0.788422</td>\n      <td>0.824742</td>\n      <td>0.831279</td>\n      <td>0.816265</td>\n      <td>0.013093</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>22.814939</td>\n      <td>3.710902</td>\n      <td>0.035637</td>\n      <td>0.011206</td>\n      <td>12</td>\n      <td>65</td>\n      <td>40</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.872372</td>\n      <td>0.857044</td>\n      <td>...</td>\n      <td>0.816400</td>\n      <td>0.809913</td>\n      <td>0.831422</td>\n      <td>0.807055</td>\n      <td>0.827783</td>\n      <td>0.788422</td>\n      <td>0.824729</td>\n      <td>0.831279</td>\n      <td>0.816274</td>\n      <td>0.013009</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22.044125</td>\n      <td>3.784975</td>\n      <td>0.044423</td>\n      <td>0.017071</td>\n      <td>12</td>\n      <td>65</td>\n      <td>50</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.872372</td>\n      <td>0.857044</td>\n      <td>...</td>\n      <td>0.816400</td>\n      <td>0.809913</td>\n      <td>0.830847</td>\n      <td>0.806977</td>\n      <td>0.827783</td>\n      <td>0.788455</td>\n      <td>0.824806</td>\n      <td>0.831117</td>\n      <td>0.816285</td>\n      <td>0.013091</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>22.427337</td>\n      <td>4.067506</td>\n      <td>0.045399</td>\n      <td>0.019666</td>\n      <td>12</td>\n      <td>65</td>\n      <td>100</td>\n      <td>{'model__max_depth': 12, 'model__min_samples_l...</td>\n      <td>0.873352</td>\n      <td>0.857242</td>\n      <td>...</td>\n      <td>0.816400</td>\n      <td>0.809913</td>\n      <td>0.831010</td>\n      <td>0.807055</td>\n      <td>0.827866</td>\n      <td>0.788422</td>\n      <td>0.825141</td>\n      <td>0.831279</td>\n      <td>0.816255</td>\n      <td>0.013049</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.543605</td>\n      <td>2.882263</td>\n      <td>0.044954</td>\n      <td>0.022065</td>\n      <td>18</td>\n      <td>25</td>\n      <td>30</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.921519</td>\n      <td>0.905130</td>\n      <td>...</td>\n      <td>0.901173</td>\n      <td>0.864709</td>\n      <td>0.887544</td>\n      <td>0.875173</td>\n      <td>0.889674</td>\n      <td>0.861784</td>\n      <td>0.898823</td>\n      <td>0.906114</td>\n      <td>0.890306</td>\n      <td>0.014709</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>22.343041</td>\n      <td>3.493467</td>\n      <td>0.052234</td>\n      <td>0.019373</td>\n      <td>18</td>\n      <td>25</td>\n      <td>40</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.922774</td>\n      <td>0.905182</td>\n      <td>...</td>\n      <td>0.902610</td>\n      <td>0.864837</td>\n      <td>0.887427</td>\n      <td>0.875173</td>\n      <td>0.889724</td>\n      <td>0.861897</td>\n      <td>0.898870</td>\n      <td>0.906541</td>\n      <td>0.890303</td>\n      <td>0.014733</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>22.614305</td>\n      <td>3.455855</td>\n      <td>0.043447</td>\n      <td>0.019811</td>\n      <td>18</td>\n      <td>25</td>\n      <td>50</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.921755</td>\n      <td>0.908207</td>\n      <td>...</td>\n      <td>0.901056</td>\n      <td>0.864183</td>\n      <td>0.887410</td>\n      <td>0.875023</td>\n      <td>0.889633</td>\n      <td>0.862355</td>\n      <td>0.898823</td>\n      <td>0.906672</td>\n      <td>0.890330</td>\n      <td>0.014695</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>22.665560</td>\n      <td>4.221708</td>\n      <td>0.049305</td>\n      <td>0.019176</td>\n      <td>18</td>\n      <td>25</td>\n      <td>100</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.908099</td>\n      <td>0.889818</td>\n      <td>...</td>\n      <td>0.887559</td>\n      <td>0.850618</td>\n      <td>0.872152</td>\n      <td>0.860879</td>\n      <td>0.872803</td>\n      <td>0.849054</td>\n      <td>0.880255</td>\n      <td>0.889573</td>\n      <td>0.873801</td>\n      <td>0.012915</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>22.201316</td>\n      <td>3.953323</td>\n      <td>0.043935</td>\n      <td>0.016769</td>\n      <td>18</td>\n      <td>45</td>\n      <td>30</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.886518</td>\n      <td>0.882927</td>\n      <td>...</td>\n      <td>0.884264</td>\n      <td>0.847256</td>\n      <td>0.872731</td>\n      <td>0.853216</td>\n      <td>0.877608</td>\n      <td>0.843249</td>\n      <td>0.872664</td>\n      <td>0.882483</td>\n      <td>0.869556</td>\n      <td>0.012348</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>22.439051</td>\n      <td>4.079740</td>\n      <td>0.045888</td>\n      <td>0.017870</td>\n      <td>18</td>\n      <td>45</td>\n      <td>40</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.888131</td>\n      <td>0.881916</td>\n      <td>...</td>\n      <td>0.884303</td>\n      <td>0.847225</td>\n      <td>0.872511</td>\n      <td>0.853478</td>\n      <td>0.877509</td>\n      <td>0.843036</td>\n      <td>0.873328</td>\n      <td>0.882483</td>\n      <td>0.869567</td>\n      <td>0.012396</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>22.441004</td>\n      <td>3.756601</td>\n      <td>0.044423</td>\n      <td>0.016618</td>\n      <td>18</td>\n      <td>45</td>\n      <td>50</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.886099</td>\n      <td>0.880912</td>\n      <td>...</td>\n      <td>0.883131</td>\n      <td>0.847577</td>\n      <td>0.872980</td>\n      <td>0.853599</td>\n      <td>0.877550</td>\n      <td>0.843446</td>\n      <td>0.872923</td>\n      <td>0.882483</td>\n      <td>0.869605</td>\n      <td>0.012295</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>22.276493</td>\n      <td>3.767305</td>\n      <td>0.049305</td>\n      <td>0.017943</td>\n      <td>18</td>\n      <td>45</td>\n      <td>100</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.891960</td>\n      <td>0.881916</td>\n      <td>...</td>\n      <td>0.882853</td>\n      <td>0.844954</td>\n      <td>0.871960</td>\n      <td>0.852944</td>\n      <td>0.875982</td>\n      <td>0.840319</td>\n      <td>0.872106</td>\n      <td>0.879765</td>\n      <td>0.868358</td>\n      <td>0.012377</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21.999702</td>\n      <td>3.997806</td>\n      <td>0.043936</td>\n      <td>0.017217</td>\n      <td>18</td>\n      <td>65</td>\n      <td>30</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.882215</td>\n      <td>0.866200</td>\n      <td>...</td>\n      <td>0.862757</td>\n      <td>0.856041</td>\n      <td>0.854206</td>\n      <td>0.848809</td>\n      <td>0.860961</td>\n      <td>0.837465</td>\n      <td>0.858113</td>\n      <td>0.862473</td>\n      <td>0.854604</td>\n      <td>0.006118</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22.387307</td>\n      <td>3.221220</td>\n      <td>0.045400</td>\n      <td>0.019666</td>\n      <td>18</td>\n      <td>65</td>\n      <td>40</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.882215</td>\n      <td>0.865296</td>\n      <td>...</td>\n      <td>0.862757</td>\n      <td>0.856389</td>\n      <td>0.854206</td>\n      <td>0.849477</td>\n      <td>0.860919</td>\n      <td>0.837465</td>\n      <td>0.858350</td>\n      <td>0.862104</td>\n      <td>0.854571</td>\n      <td>0.006062</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22.425872</td>\n      <td>3.747155</td>\n      <td>0.045400</td>\n      <td>0.021518</td>\n      <td>18</td>\n      <td>65</td>\n      <td>50</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.882215</td>\n      <td>0.866302</td>\n      <td>...</td>\n      <td>0.862757</td>\n      <td>0.856389</td>\n      <td>0.853642</td>\n      <td>0.849466</td>\n      <td>0.860919</td>\n      <td>0.837465</td>\n      <td>0.858350</td>\n      <td>0.862473</td>\n      <td>0.854647</td>\n      <td>0.006203</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>22.120813</td>\n      <td>3.743303</td>\n      <td>0.047352</td>\n      <td>0.019324</td>\n      <td>18</td>\n      <td>65</td>\n      <td>100</td>\n      <td>{'model__max_depth': 18, 'model__min_samples_l...</td>\n      <td>0.882215</td>\n      <td>0.866200</td>\n      <td>...</td>\n      <td>0.862757</td>\n      <td>0.856399</td>\n      <td>0.854143</td>\n      <td>0.849477</td>\n      <td>0.860961</td>\n      <td>0.837465</td>\n      <td>0.858350</td>\n      <td>0.862104</td>\n      <td>0.854722</td>\n      <td>0.006119</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>22.022046</td>\n      <td>3.208034</td>\n      <td>0.045888</td>\n      <td>0.021008</td>\n      <td>24</td>\n      <td>25</td>\n      <td>30</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.913252</td>\n      <td>0.920423</td>\n      <td>...</td>\n      <td>0.913278</td>\n      <td>0.906904</td>\n      <td>0.909051</td>\n      <td>0.913083</td>\n      <td>0.912302</td>\n      <td>0.914876</td>\n      <td>0.923966</td>\n      <td>0.916056</td>\n      <td>0.914251</td>\n      <td>0.006004</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>22.562067</td>\n      <td>3.439203</td>\n      <td>0.046865</td>\n      <td>0.018318</td>\n      <td>24</td>\n      <td>25</td>\n      <td>40</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.912655</td>\n      <td>0.919991</td>\n      <td>...</td>\n      <td>0.913020</td>\n      <td>0.906904</td>\n      <td>0.908591</td>\n      <td>0.912431</td>\n      <td>0.912276</td>\n      <td>0.914771</td>\n      <td>0.924482</td>\n      <td>0.916186</td>\n      <td>0.914208</td>\n      <td>0.006029</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>22.681671</td>\n      <td>3.605672</td>\n      <td>0.044912</td>\n      <td>0.017356</td>\n      <td>24</td>\n      <td>25</td>\n      <td>50</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.914267</td>\n      <td>0.920069</td>\n      <td>...</td>\n      <td>0.913253</td>\n      <td>0.907036</td>\n      <td>0.908505</td>\n      <td>0.913091</td>\n      <td>0.912063</td>\n      <td>0.915120</td>\n      <td>0.924005</td>\n      <td>0.915961</td>\n      <td>0.914079</td>\n      <td>0.005958</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>22.384378</td>\n      <td>3.229668</td>\n      <td>0.045887</td>\n      <td>0.022069</td>\n      <td>24</td>\n      <td>25</td>\n      <td>100</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.891904</td>\n      <td>0.893023</td>\n      <td>...</td>\n      <td>0.897507</td>\n      <td>0.888345</td>\n      <td>0.892115</td>\n      <td>0.893608</td>\n      <td>0.892755</td>\n      <td>0.895974</td>\n      <td>0.901939</td>\n      <td>0.896095</td>\n      <td>0.894375</td>\n      <td>0.005150</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>22.490309</td>\n      <td>4.138474</td>\n      <td>0.043936</td>\n      <td>0.017655</td>\n      <td>24</td>\n      <td>45</td>\n      <td>30</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.878914</td>\n      <td>0.884785</td>\n      <td>...</td>\n      <td>0.886596</td>\n      <td>0.881620</td>\n      <td>0.885708</td>\n      <td>0.883787</td>\n      <td>0.888625</td>\n      <td>0.886642</td>\n      <td>0.892216</td>\n      <td>0.885733</td>\n      <td>0.886749</td>\n      <td>0.003843</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>22.349718</td>\n      <td>3.203864</td>\n      <td>0.050282</td>\n      <td>0.024617</td>\n      <td>24</td>\n      <td>45</td>\n      <td>40</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.875571</td>\n      <td>0.887063</td>\n      <td>...</td>\n      <td>0.888905</td>\n      <td>0.881274</td>\n      <td>0.885593</td>\n      <td>0.883589</td>\n      <td>0.888553</td>\n      <td>0.886642</td>\n      <td>0.892336</td>\n      <td>0.887280</td>\n      <td>0.886889</td>\n      <td>0.003873</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>22.705951</td>\n      <td>3.287665</td>\n      <td>0.047353</td>\n      <td>0.018518</td>\n      <td>24</td>\n      <td>45</td>\n      <td>50</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.877377</td>\n      <td>0.886526</td>\n      <td>...</td>\n      <td>0.888786</td>\n      <td>0.881355</td>\n      <td>0.885770</td>\n      <td>0.882511</td>\n      <td>0.888418</td>\n      <td>0.886332</td>\n      <td>0.892134</td>\n      <td>0.885733</td>\n      <td>0.886771</td>\n      <td>0.003876</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>22.345811</td>\n      <td>2.793161</td>\n      <td>0.044425</td>\n      <td>0.018774</td>\n      <td>24</td>\n      <td>45</td>\n      <td>100</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.880380</td>\n      <td>0.886105</td>\n      <td>...</td>\n      <td>0.884932</td>\n      <td>0.879495</td>\n      <td>0.884746</td>\n      <td>0.882850</td>\n      <td>0.887182</td>\n      <td>0.883258</td>\n      <td>0.891435</td>\n      <td>0.884391</td>\n      <td>0.885372</td>\n      <td>0.003760</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>22.405531</td>\n      <td>3.414206</td>\n      <td>0.042959</td>\n      <td>0.017897</td>\n      <td>24</td>\n      <td>65</td>\n      <td>30</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.871847</td>\n      <td>0.872911</td>\n      <td>...</td>\n      <td>0.866205</td>\n      <td>0.869746</td>\n      <td>0.861467</td>\n      <td>0.850984</td>\n      <td>0.872865</td>\n      <td>0.859196</td>\n      <td>0.866323</td>\n      <td>0.862648</td>\n      <td>0.864073</td>\n      <td>0.004628</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>22.270147</td>\n      <td>3.869660</td>\n      <td>0.048816</td>\n      <td>0.019817</td>\n      <td>24</td>\n      <td>65</td>\n      <td>40</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.873030</td>\n      <td>0.873019</td>\n      <td>...</td>\n      <td>0.866205</td>\n      <td>0.869171</td>\n      <td>0.861971</td>\n      <td>0.850984</td>\n      <td>0.872874</td>\n      <td>0.858819</td>\n      <td>0.866108</td>\n      <td>0.862648</td>\n      <td>0.864059</td>\n      <td>0.004658</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>22.509347</td>\n      <td>3.156899</td>\n      <td>0.043936</td>\n      <td>0.016769</td>\n      <td>24</td>\n      <td>65</td>\n      <td>50</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.871847</td>\n      <td>0.873019</td>\n      <td>...</td>\n      <td>0.866205</td>\n      <td>0.868705</td>\n      <td>0.861436</td>\n      <td>0.850975</td>\n      <td>0.872806</td>\n      <td>0.858861</td>\n      <td>0.866108</td>\n      <td>0.862648</td>\n      <td>0.863981</td>\n      <td>0.004490</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>17.444134</td>\n      <td>1.225269</td>\n      <td>0.033684</td>\n      <td>0.005672</td>\n      <td>24</td>\n      <td>65</td>\n      <td>100</td>\n      <td>{'model__max_depth': 24, 'model__min_samples_l...</td>\n      <td>0.873030</td>\n      <td>0.873019</td>\n      <td>...</td>\n      <td>0.865013</td>\n      <td>0.869334</td>\n      <td>0.861436</td>\n      <td>0.850975</td>\n      <td>0.872806</td>\n      <td>0.858767</td>\n      <td>0.866323</td>\n      <td>0.864809</td>\n      <td>0.864085</td>\n      <td>0.004636</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>16.922285</td>\n      <td>0.178975</td>\n      <td>0.034171</td>\n      <td>0.006097</td>\n      <td>32</td>\n      <td>25</td>\n      <td>30</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.908255</td>\n      <td>0.921143</td>\n      <td>...</td>\n      <td>0.917527</td>\n      <td>0.923265</td>\n      <td>0.916570</td>\n      <td>0.921309</td>\n      <td>0.917249</td>\n      <td>0.923271</td>\n      <td>0.928322</td>\n      <td>0.916353</td>\n      <td>0.920859</td>\n      <td>0.004020</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>16.879326</td>\n      <td>0.177251</td>\n      <td>0.033684</td>\n      <td>0.005672</td>\n      <td>32</td>\n      <td>25</td>\n      <td>40</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.908701</td>\n      <td>0.922514</td>\n      <td>...</td>\n      <td>0.917812</td>\n      <td>0.922700</td>\n      <td>0.917160</td>\n      <td>0.921413</td>\n      <td>0.917309</td>\n      <td>0.923271</td>\n      <td>0.928551</td>\n      <td>0.916676</td>\n      <td>0.920752</td>\n      <td>0.003964</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>17.214696</td>\n      <td>0.217474</td>\n      <td>0.033196</td>\n      <td>0.005167</td>\n      <td>32</td>\n      <td>25</td>\n      <td>50</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.909836</td>\n      <td>0.921143</td>\n      <td>...</td>\n      <td>0.917512</td>\n      <td>0.922600</td>\n      <td>0.917226</td>\n      <td>0.921221</td>\n      <td>0.917319</td>\n      <td>0.923254</td>\n      <td>0.928058</td>\n      <td>0.915894</td>\n      <td>0.920740</td>\n      <td>0.003918</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>18.189120</td>\n      <td>1.214581</td>\n      <td>0.035148</td>\n      <td>0.007811</td>\n      <td>32</td>\n      <td>25</td>\n      <td>100</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.888410</td>\n      <td>0.891118</td>\n      <td>...</td>\n      <td>0.901106</td>\n      <td>0.903330</td>\n      <td>0.899210</td>\n      <td>0.898180</td>\n      <td>0.897553</td>\n      <td>0.901529</td>\n      <td>0.905446</td>\n      <td>0.897383</td>\n      <td>0.899617</td>\n      <td>0.003883</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>17.129755</td>\n      <td>0.177034</td>\n      <td>0.033196</td>\n      <td>0.005169</td>\n      <td>32</td>\n      <td>45</td>\n      <td>30</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.870227</td>\n      <td>0.882842</td>\n      <td>...</td>\n      <td>0.890294</td>\n      <td>0.892983</td>\n      <td>0.890072</td>\n      <td>0.886390</td>\n      <td>0.892707</td>\n      <td>0.893218</td>\n      <td>0.894093</td>\n      <td>0.886165</td>\n      <td>0.890548</td>\n      <td>0.003229</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>17.226900</td>\n      <td>0.316855</td>\n      <td>0.034661</td>\n      <td>0.009352</td>\n      <td>32</td>\n      <td>45</td>\n      <td>40</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.873167</td>\n      <td>0.885499</td>\n      <td>...</td>\n      <td>0.889940</td>\n      <td>0.892625</td>\n      <td>0.890527</td>\n      <td>0.886936</td>\n      <td>0.892700</td>\n      <td>0.893305</td>\n      <td>0.893619</td>\n      <td>0.886165</td>\n      <td>0.890602</td>\n      <td>0.003139</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>16.995998</td>\n      <td>0.176347</td>\n      <td>0.036127</td>\n      <td>0.010655</td>\n      <td>32</td>\n      <td>45</td>\n      <td>50</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.873088</td>\n      <td>0.885499</td>\n      <td>...</td>\n      <td>0.889940</td>\n      <td>0.892955</td>\n      <td>0.890072</td>\n      <td>0.886596</td>\n      <td>0.892762</td>\n      <td>0.892925</td>\n      <td>0.894386</td>\n      <td>0.886165</td>\n      <td>0.890398</td>\n      <td>0.003267</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>17.221531</td>\n      <td>0.182465</td>\n      <td>0.035637</td>\n      <td>0.012494</td>\n      <td>32</td>\n      <td>45</td>\n      <td>100</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.877323</td>\n      <td>0.885499</td>\n      <td>...</td>\n      <td>0.885911</td>\n      <td>0.890013</td>\n      <td>0.889634</td>\n      <td>0.885725</td>\n      <td>0.890383</td>\n      <td>0.889931</td>\n      <td>0.893871</td>\n      <td>0.883757</td>\n      <td>0.888865</td>\n      <td>0.003071</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>17.625734</td>\n      <td>0.911352</td>\n      <td>0.035147</td>\n      <td>0.006764</td>\n      <td>32</td>\n      <td>65</td>\n      <td>30</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.869488</td>\n      <td>0.872739</td>\n      <td>...</td>\n      <td>0.866205</td>\n      <td>0.869747</td>\n      <td>0.864637</td>\n      <td>0.850984</td>\n      <td>0.872806</td>\n      <td>0.867310</td>\n      <td>0.867019</td>\n      <td>0.863052</td>\n      <td>0.865177</td>\n      <td>0.004605</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>17.014060</td>\n      <td>0.190006</td>\n      <td>0.031243</td>\n      <td>0.003905</td>\n      <td>32</td>\n      <td>65</td>\n      <td>40</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.868316</td>\n      <td>0.873212</td>\n      <td>...</td>\n      <td>0.866202</td>\n      <td>0.870087</td>\n      <td>0.864164</td>\n      <td>0.850975</td>\n      <td>0.872806</td>\n      <td>0.867207</td>\n      <td>0.866928</td>\n      <td>0.862648</td>\n      <td>0.865075</td>\n      <td>0.004749</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>16.935953</td>\n      <td>0.136915</td>\n      <td>0.033683</td>\n      <td>0.005671</td>\n      <td>32</td>\n      <td>65</td>\n      <td>50</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.869488</td>\n      <td>0.872739</td>\n      <td>...</td>\n      <td>0.866205</td>\n      <td>0.869747</td>\n      <td>0.864164</td>\n      <td>0.850584</td>\n      <td>0.872806</td>\n      <td>0.867207</td>\n      <td>0.866683</td>\n      <td>0.863052</td>\n      <td>0.865146</td>\n      <td>0.004695</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>16.797317</td>\n      <td>0.570532</td>\n      <td>0.032217</td>\n      <td>0.005438</td>\n      <td>32</td>\n      <td>65</td>\n      <td>100</td>\n      <td>{'model__max_depth': 32, 'model__min_samples_l...</td>\n      <td>0.869488</td>\n      <td>0.872275</td>\n      <td>...</td>\n      <td>0.866205</td>\n      <td>0.870199</td>\n      <td>0.864164</td>\n      <td>0.850984</td>\n      <td>0.872806</td>\n      <td>0.867207</td>\n      <td>0.866643</td>\n      <td>0.863158</td>\n      <td>0.865145</td>\n      <td>0.004764</td>\n    </tr>\n  </tbody>\n</table>\n<p>48 rows  215 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_gs_cv = pd.DataFrame(model_6_gs.cv_results_)\n",
    "model_6_gs_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model_6_gs_cv.to_pickle('../../data/temp/model_6.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9061267035868111,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n                 ('model',\n                  DecisionTreeClassifier(max_depth=32, min_samples_leaf=25,\n                                         min_samples_split=50))]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_gs.best_score_, model_6_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model seven"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('selection', Pipeline(steps=[('feat_selection',\n                    SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n  ('model', ExtraTreeClassifier())],\n 'verbose': False,\n 'selection': Pipeline(steps=[('feat_selection',\n                  SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))]),\n 'model': ExtraTreeClassifier(),\n 'selection__memory': None,\n 'selection__steps': [('feat_selection',\n   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))],\n 'selection__verbose': False,\n 'selection__feat_selection': SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>),\n 'selection__feat_selection__k': 10,\n 'selection__feat_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>,\n 'model__ccp_alpha': 0.0,\n 'model__class_weight': None,\n 'model__criterion': 'gini',\n 'model__max_depth': None,\n 'model__max_features': 'auto',\n 'model__max_leaf_nodes': None,\n 'model__min_impurity_decrease': 0.0,\n 'model__min_impurity_split': None,\n 'model__min_samples_leaf': 1,\n 'model__min_samples_split': 2,\n 'model__min_weight_fraction_leaf': 0.0,\n 'model__random_state': None,\n 'model__splitter': 'random'}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7 = Pipeline(steps=[('selection', feature_pipeline),\n",
    "                          ('model', ExtraTreeClassifier())])\n",
    "model_7.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=RepeatedKFold(n_repeats=8, n_splits=4, random_state=1),\n             estimator=Pipeline(steps=[('selection',\n                                        Pipeline(steps=[('feat_selection',\n                                                         SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n                                       ('model', ExtraTreeClassifier())]),\n             n_jobs=-1,\n             param_grid={'model__ccp_alpha': array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n       0.71428571, 0.85714286, 1.        ]),\n                         'model__max_depth': [24, 32, 36],\n                         'model__min_samples_leaf': [20, 25],\n                         'model__min_samples_split': [50, 100, 120]},\n             refit='f1', return_train_score=True,\n             scoring={'f1': make_scorer(f1_score),\n                      'precision': make_scorer(precision_score),\n                      'recall': make_scorer(recall_score)})"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_7 = {'model__ccp_alpha': np.linspace(0, 1, 8),\n",
    "          'model__max_depth': [24, 32, 36],\n",
    "          'model__min_samples_split': [50, 100, 120],\n",
    "          'model__min_samples_leaf': [20, 25]}\n",
    "\n",
    "model_7_gs = GridSearchCV(estimator=model_7, cv=cv, n_jobs=-1,\n",
    "                          param_grid=grid_7,\n",
    "                          scoring={'precision': make_scorer(precision_score),\n",
    "                                   'recall': make_scorer(recall_score),\n",
    "                                   'f1': make_scorer(f1_score)},\n",
    "                          refit='f1',\n",
    "                          return_train_score=True)\n",
    "model_7_gs.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        15.151625      1.761997         0.034659        0.026120   \n1        16.235350      0.257656         0.034960        0.006516   \n2        16.255450      0.209759         0.034661        0.009357   \n3        16.398482      0.227114         0.033195        0.006476   \n4        16.462432      0.227856         0.033196        0.006476   \n..             ...           ...              ...             ...   \n139      16.138721      0.336400         0.028802        0.005672   \n140      15.485799      0.848265         0.027826        0.006458   \n141      16.201674      0.721876         0.029778        0.005998   \n142      16.073288      0.174328         0.030266        0.005436   \n143      15.757708      1.191821         0.028314        0.006098   \n\n    param_model__ccp_alpha param_model__max_depth  \\\n0                      0.0                     24   \n1                      0.0                     24   \n2                      0.0                     24   \n3                      0.0                     24   \n4                      0.0                     24   \n..                     ...                    ...   \n139                    1.0                     36   \n140                    1.0                     36   \n141                    1.0                     36   \n142                    1.0                     36   \n143                    1.0                     36   \n\n    param_model__min_samples_leaf param_model__min_samples_split  \\\n0                              20                             50   \n1                              20                            100   \n2                              20                            120   \n3                              25                             50   \n4                              25                            100   \n..                            ...                            ...   \n139                            20                            100   \n140                            20                            120   \n141                            25                             50   \n142                            25                            100   \n143                            25                            120   \n\n                                                params  split0_test_precision  \\\n0    {'model__ccp_alpha': 0.0, 'model__max_depth': ...               0.775910   \n1    {'model__ccp_alpha': 0.0, 'model__max_depth': ...               0.757220   \n2    {'model__ccp_alpha': 0.0, 'model__max_depth': ...               0.774400   \n3    {'model__ccp_alpha': 0.0, 'model__max_depth': ...               0.751078   \n4    {'model__ccp_alpha': 0.0, 'model__max_depth': ...               0.772947   \n..                                                 ...                    ...   \n139  {'model__ccp_alpha': 1.0, 'model__max_depth': ...               0.574429   \n140  {'model__ccp_alpha': 1.0, 'model__max_depth': ...               0.574429   \n141  {'model__ccp_alpha': 1.0, 'model__max_depth': ...               0.574429   \n142  {'model__ccp_alpha': 1.0, 'model__max_depth': ...               0.574429   \n143  {'model__ccp_alpha': 1.0, 'model__max_depth': ...               0.574429   \n\n     ...  split24_train_f1  split25_train_f1  split26_train_f1  \\\n0    ...          0.713627          0.725147          0.726647   \n1    ...          0.709487          0.728716          0.720075   \n2    ...          0.712308          0.714919          0.720862   \n3    ...          0.726622          0.732894          0.690675   \n4    ...          0.733550          0.720973          0.697457   \n..   ...               ...               ...               ...   \n139  ...          0.733031          0.733559          0.733064   \n140  ...          0.733031          0.733559          0.733064   \n141  ...          0.733031          0.733559          0.733064   \n142  ...          0.733031          0.733559          0.733064   \n143  ...          0.733031          0.733559          0.733064   \n\n     split27_train_f1  split28_train_f1  split29_train_f1  split30_train_f1  \\\n0            0.718803          0.713247          0.728694          0.735415   \n1            0.728174          0.723524          0.701474          0.733845   \n2            0.709497          0.722487          0.717481          0.729643   \n3            0.704882          0.721719          0.724515          0.716950   \n4            0.704951          0.720861          0.728964          0.696982   \n..                ...               ...               ...               ...   \n139          0.733507          0.731972          0.733757          0.732899   \n140          0.733507          0.731972          0.733757          0.732899   \n141          0.733507          0.731972          0.733757          0.732899   \n142          0.733507          0.731972          0.733757          0.732899   \n143          0.733507          0.731972          0.733757          0.732899   \n\n     split31_train_f1  mean_train_f1  std_train_f1  \n0            0.722336       0.721057      0.011850  \n1            0.693212       0.715449      0.012094  \n2            0.729367       0.719647      0.009820  \n3            0.723466       0.717103      0.014821  \n4            0.677092       0.713086      0.014797  \n..                ...            ...           ...  \n139          0.734530       0.733290      0.000995  \n140          0.734530       0.733290      0.000995  \n141          0.734530       0.733290      0.000995  \n142          0.734530       0.733290      0.000995  \n143          0.734530       0.733290      0.000995  \n\n[144 rows x 216 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_model__ccp_alpha</th>\n      <th>param_model__max_depth</th>\n      <th>param_model__min_samples_leaf</th>\n      <th>param_model__min_samples_split</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>...</th>\n      <th>split24_train_f1</th>\n      <th>split25_train_f1</th>\n      <th>split26_train_f1</th>\n      <th>split27_train_f1</th>\n      <th>split28_train_f1</th>\n      <th>split29_train_f1</th>\n      <th>split30_train_f1</th>\n      <th>split31_train_f1</th>\n      <th>mean_train_f1</th>\n      <th>std_train_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.151625</td>\n      <td>1.761997</td>\n      <td>0.034659</td>\n      <td>0.026120</td>\n      <td>0.0</td>\n      <td>24</td>\n      <td>20</td>\n      <td>50</td>\n      <td>{'model__ccp_alpha': 0.0, 'model__max_depth': ...</td>\n      <td>0.775910</td>\n      <td>...</td>\n      <td>0.713627</td>\n      <td>0.725147</td>\n      <td>0.726647</td>\n      <td>0.718803</td>\n      <td>0.713247</td>\n      <td>0.728694</td>\n      <td>0.735415</td>\n      <td>0.722336</td>\n      <td>0.721057</td>\n      <td>0.011850</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16.235350</td>\n      <td>0.257656</td>\n      <td>0.034960</td>\n      <td>0.006516</td>\n      <td>0.0</td>\n      <td>24</td>\n      <td>20</td>\n      <td>100</td>\n      <td>{'model__ccp_alpha': 0.0, 'model__max_depth': ...</td>\n      <td>0.757220</td>\n      <td>...</td>\n      <td>0.709487</td>\n      <td>0.728716</td>\n      <td>0.720075</td>\n      <td>0.728174</td>\n      <td>0.723524</td>\n      <td>0.701474</td>\n      <td>0.733845</td>\n      <td>0.693212</td>\n      <td>0.715449</td>\n      <td>0.012094</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16.255450</td>\n      <td>0.209759</td>\n      <td>0.034661</td>\n      <td>0.009357</td>\n      <td>0.0</td>\n      <td>24</td>\n      <td>20</td>\n      <td>120</td>\n      <td>{'model__ccp_alpha': 0.0, 'model__max_depth': ...</td>\n      <td>0.774400</td>\n      <td>...</td>\n      <td>0.712308</td>\n      <td>0.714919</td>\n      <td>0.720862</td>\n      <td>0.709497</td>\n      <td>0.722487</td>\n      <td>0.717481</td>\n      <td>0.729643</td>\n      <td>0.729367</td>\n      <td>0.719647</td>\n      <td>0.009820</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.398482</td>\n      <td>0.227114</td>\n      <td>0.033195</td>\n      <td>0.006476</td>\n      <td>0.0</td>\n      <td>24</td>\n      <td>25</td>\n      <td>50</td>\n      <td>{'model__ccp_alpha': 0.0, 'model__max_depth': ...</td>\n      <td>0.751078</td>\n      <td>...</td>\n      <td>0.726622</td>\n      <td>0.732894</td>\n      <td>0.690675</td>\n      <td>0.704882</td>\n      <td>0.721719</td>\n      <td>0.724515</td>\n      <td>0.716950</td>\n      <td>0.723466</td>\n      <td>0.717103</td>\n      <td>0.014821</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.462432</td>\n      <td>0.227856</td>\n      <td>0.033196</td>\n      <td>0.006476</td>\n      <td>0.0</td>\n      <td>24</td>\n      <td>25</td>\n      <td>100</td>\n      <td>{'model__ccp_alpha': 0.0, 'model__max_depth': ...</td>\n      <td>0.772947</td>\n      <td>...</td>\n      <td>0.733550</td>\n      <td>0.720973</td>\n      <td>0.697457</td>\n      <td>0.704951</td>\n      <td>0.720861</td>\n      <td>0.728964</td>\n      <td>0.696982</td>\n      <td>0.677092</td>\n      <td>0.713086</td>\n      <td>0.014797</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>16.138721</td>\n      <td>0.336400</td>\n      <td>0.028802</td>\n      <td>0.005672</td>\n      <td>1.0</td>\n      <td>36</td>\n      <td>20</td>\n      <td>100</td>\n      <td>{'model__ccp_alpha': 1.0, 'model__max_depth': ...</td>\n      <td>0.574429</td>\n      <td>...</td>\n      <td>0.733031</td>\n      <td>0.733559</td>\n      <td>0.733064</td>\n      <td>0.733507</td>\n      <td>0.731972</td>\n      <td>0.733757</td>\n      <td>0.732899</td>\n      <td>0.734530</td>\n      <td>0.733290</td>\n      <td>0.000995</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>15.485799</td>\n      <td>0.848265</td>\n      <td>0.027826</td>\n      <td>0.006458</td>\n      <td>1.0</td>\n      <td>36</td>\n      <td>20</td>\n      <td>120</td>\n      <td>{'model__ccp_alpha': 1.0, 'model__max_depth': ...</td>\n      <td>0.574429</td>\n      <td>...</td>\n      <td>0.733031</td>\n      <td>0.733559</td>\n      <td>0.733064</td>\n      <td>0.733507</td>\n      <td>0.731972</td>\n      <td>0.733757</td>\n      <td>0.732899</td>\n      <td>0.734530</td>\n      <td>0.733290</td>\n      <td>0.000995</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>16.201674</td>\n      <td>0.721876</td>\n      <td>0.029778</td>\n      <td>0.005998</td>\n      <td>1.0</td>\n      <td>36</td>\n      <td>25</td>\n      <td>50</td>\n      <td>{'model__ccp_alpha': 1.0, 'model__max_depth': ...</td>\n      <td>0.574429</td>\n      <td>...</td>\n      <td>0.733031</td>\n      <td>0.733559</td>\n      <td>0.733064</td>\n      <td>0.733507</td>\n      <td>0.731972</td>\n      <td>0.733757</td>\n      <td>0.732899</td>\n      <td>0.734530</td>\n      <td>0.733290</td>\n      <td>0.000995</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>16.073288</td>\n      <td>0.174328</td>\n      <td>0.030266</td>\n      <td>0.005436</td>\n      <td>1.0</td>\n      <td>36</td>\n      <td>25</td>\n      <td>100</td>\n      <td>{'model__ccp_alpha': 1.0, 'model__max_depth': ...</td>\n      <td>0.574429</td>\n      <td>...</td>\n      <td>0.733031</td>\n      <td>0.733559</td>\n      <td>0.733064</td>\n      <td>0.733507</td>\n      <td>0.731972</td>\n      <td>0.733757</td>\n      <td>0.732899</td>\n      <td>0.734530</td>\n      <td>0.733290</td>\n      <td>0.000995</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>15.757708</td>\n      <td>1.191821</td>\n      <td>0.028314</td>\n      <td>0.006098</td>\n      <td>1.0</td>\n      <td>36</td>\n      <td>25</td>\n      <td>120</td>\n      <td>{'model__ccp_alpha': 1.0, 'model__max_depth': ...</td>\n      <td>0.574429</td>\n      <td>...</td>\n      <td>0.733031</td>\n      <td>0.733559</td>\n      <td>0.733064</td>\n      <td>0.733507</td>\n      <td>0.731972</td>\n      <td>0.733757</td>\n      <td>0.732899</td>\n      <td>0.734530</td>\n      <td>0.733290</td>\n      <td>0.000995</td>\n    </tr>\n  </tbody>\n</table>\n<p>144 rows  216 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_gs_cv = pd.DataFrame(model_7_gs.cv_results_)\n",
    "model_7_gs_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model_7_gs_cv.to_pickle('../../data/temp/model_7.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7332832616479414,\n Pipeline(steps=[('selection',\n                  Pipeline(steps=[('feat_selection',\n                                   SelectKBest(score_func=<function mutual_info_classif at 0x0000026E1CF99D90>))])),\n                 ('model',\n                  ExtraTreeClassifier(ccp_alpha=0.14285714285714285,\n                                      max_depth=24, min_samples_leaf=20,\n                                      min_samples_split=50))]))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_gs.best_score_, model_7_gs.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}